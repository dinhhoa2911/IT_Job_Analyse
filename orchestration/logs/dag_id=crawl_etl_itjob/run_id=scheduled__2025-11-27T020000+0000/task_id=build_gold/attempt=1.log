[2025-11-28T07:55:27.611+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-28T07:55:27.672+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: crawl_etl_itjob.build_gold scheduled__2025-11-27T02:00:00+00:00 [queued]>
[2025-11-28T07:55:27.690+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: crawl_etl_itjob.build_gold scheduled__2025-11-27T02:00:00+00:00 [queued]>
[2025-11-28T07:55:27.691+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-11-28T07:55:27.725+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): build_gold> on 2025-11-27 02:00:00+00:00
[2025-11-28T07:55:27.732+0000] {standard_task_runner.py:72} INFO - Started process 84 to run task
[2025-11-28T07:55:27.740+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'crawl_etl_itjob', 'build_gold', 'scheduled__2025-11-27T02:00:00+00:00', '--job-id', '235', '--raw', '--subdir', 'DAGS_FOLDER/Crawl_ETL_ITJob.py', '--cfg-path', '/tmp/tmpvbj7yv7c']
[2025-11-28T07:55:27.742+0000] {standard_task_runner.py:105} INFO - Job 235: Subtask build_gold
[2025-11-28T07:55:27.780+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:209: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2025-11-28T07:55:27.901+0000] {task_command.py:467} INFO - Running <TaskInstance: crawl_etl_itjob.build_gold scheduled__2025-11-27T02:00:00+00:00 [running]> on host a1de7f96d4f1
[2025-11-28T07:55:27.902+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:470: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  if conf.get("database", "sql_alchemy_conn") == "none://":

[2025-11-28T07:55:28.710+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='alert@datateam.local' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='crawl_etl_itjob' AIRFLOW_CTX_TASK_ID='build_gold' AIRFLOW_CTX_EXECUTION_DATE='2025-11-27T02:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-27T02:00:00+00:00'
[2025-11-28T07:55:28.711+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-11-28T07:55:28.731+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-11-28T07:55:28.733+0000] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "\n        docker exec spark-submit bash -c '\n        /opt/spark/bin/spark-submit         --master spark://spark-master:7077         --deploy-mode client         --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0         /opt/spark/scripts/Build_Gold.py\n        '\n        "]
[2025-11-28T07:55:28.747+0000] {subprocess.py:99} INFO - Output:
[2025-11-28T07:55:33.055+0000] {subprocess.py:106} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-11-28T07:55:33.182+0000] {subprocess.py:106} INFO - Ivy Default Cache set to: /home/spark/.ivy2/cache
[2025-11-28T07:55:33.183+0000] {subprocess.py:106} INFO - The jars for the packages stored in: /home/spark/.ivy2/jars
[2025-11-28T07:55:33.193+0000] {subprocess.py:106} INFO - org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency
[2025-11-28T07:55:33.196+0000] {subprocess.py:106} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-7c33d4d8-f8fa-41dd-b260-861df31552b8;1.0
[2025-11-28T07:55:33.198+0000] {subprocess.py:106} INFO - 	confs: [default]
[2025-11-28T07:55:33.372+0000] {subprocess.py:106} INFO - 	found org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 in central
[2025-11-28T07:55:33.394+0000] {subprocess.py:106} INFO - :: resolution report :: resolve 193ms :: artifacts dl 5ms
[2025-11-28T07:55:33.396+0000] {subprocess.py:106} INFO - 	:: modules in use:
[2025-11-28T07:55:33.397+0000] {subprocess.py:106} INFO - 	org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 from central in [default]
[2025-11-28T07:55:33.397+0000] {subprocess.py:106} INFO - 	---------------------------------------------------------------------
[2025-11-28T07:55:33.398+0000] {subprocess.py:106} INFO - 	|                  |            modules            ||   artifacts   |
[2025-11-28T07:55:33.399+0000] {subprocess.py:106} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-11-28T07:55:33.399+0000] {subprocess.py:106} INFO - 	---------------------------------------------------------------------
[2025-11-28T07:55:33.400+0000] {subprocess.py:106} INFO - 	|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |
[2025-11-28T07:55:33.401+0000] {subprocess.py:106} INFO - 	---------------------------------------------------------------------
[2025-11-28T07:55:33.401+0000] {subprocess.py:106} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-7c33d4d8-f8fa-41dd-b260-861df31552b8
[2025-11-28T07:55:33.402+0000] {subprocess.py:106} INFO - 	confs: [default]
[2025-11-28T07:55:33.409+0000] {subprocess.py:106} INFO - 	0 artifacts copied, 1 already retrieved (0kB/9ms)
[2025-11-28T07:55:33.778+0000] {subprocess.py:106} INFO - 25/11/28 07:55:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-11-28T07:55:35.268+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SparkContext: Running Spark version 3.5.3
[2025-11-28T07:55:35.270+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-28T07:55:35.271+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SparkContext: Java version 11.0.24
[2025-11-28T07:55:35.315+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO ResourceUtils: ==============================================================
[2025-11-28T07:55:35.316+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-11-28T07:55:35.317+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO ResourceUtils: ==============================================================
[2025-11-28T07:55:35.318+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SparkContext: Submitted application: Build_Gold_Layer_Star_Schema
[2025-11-28T07:55:35.359+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-11-28T07:55:35.375+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO ResourceProfile: Limiting resource is cpu
[2025-11-28T07:55:35.376+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-11-28T07:55:35.450+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SecurityManager: Changing view acls to: spark
[2025-11-28T07:55:35.451+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SecurityManager: Changing modify acls to: spark
[2025-11-28T07:55:35.452+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SecurityManager: Changing view acls groups to:
[2025-11-28T07:55:35.458+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SecurityManager: Changing modify acls groups to:
[2025-11-28T07:55:35.459+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
[2025-11-28T07:55:35.852+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO Utils: Successfully started service 'sparkDriver' on port 42535.
[2025-11-28T07:55:35.911+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SparkEnv: Registering MapOutputTracker
[2025-11-28T07:55:35.974+0000] {subprocess.py:106} INFO - 25/11/28 07:55:35 INFO SparkEnv: Registering BlockManagerMaster
[2025-11-28T07:55:36.007+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-11-28T07:55:36.008+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-11-28T07:55:36.018+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-11-28T07:55:36.060+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e0beac91-27fe-41d8-b689-153065e4f49e
[2025-11-28T07:55:36.088+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-11-28T07:55:36.119+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-11-28T07:55:36.370+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-11-28T07:55:36.482+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-11-28T07:55:36.549+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO SparkContext: Added JAR file:///home/spark/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.0.jar at spark://68d0d8c522fe:42535/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.0.jar with timestamp 1764316535251
[2025-11-28T07:55:36.557+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO SparkContext: Added file file:///home/spark/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.0.jar at spark://68d0d8c522fe:42535/files/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.0.jar with timestamp 1764316535251
[2025-11-28T07:55:36.560+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO Utils: Copying /home/spark/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.0.jar to /tmp/spark-e44a46b6-b648-44ff-bc83-4d7ea65434cc/userFiles-02bec856-1776-45f0-b8ed-10bd88d44e53/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.0.jar
[2025-11-28T07:55:36.846+0000] {subprocess.py:106} INFO - 25/11/28 07:55:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-11-28T07:55:37.006+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO TransportClientFactory: Successfully created connection to spark-master/172.30.0.6:7077 after 84 ms (0 ms spent in bootstraps)
[2025-11-28T07:55:37.270+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251128075537-0002
[2025-11-28T07:55:37.273+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251128075537-0002/0 on worker-20251128073529-172.30.0.7-37819 (172.30.0.7:37819) with 1 core(s)
[2025-11-28T07:55:37.278+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO StandaloneSchedulerBackend: Granted executor ID app-20251128075537-0002/0 on hostPort 172.30.0.7:37819 with 1 core(s), 1024.0 MiB RAM
[2025-11-28T07:55:37.294+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36705.
[2025-11-28T07:55:37.296+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO NettyBlockTransferService: Server created on 68d0d8c522fe:36705
[2025-11-28T07:55:37.298+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-11-28T07:55:37.318+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 68d0d8c522fe, 36705, None)
[2025-11-28T07:55:37.332+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO BlockManagerMasterEndpoint: Registering block manager 68d0d8c522fe:36705 with 434.4 MiB RAM, BlockManagerId(driver, 68d0d8c522fe, 36705, None)
[2025-11-28T07:55:37.338+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 68d0d8c522fe, 36705, None)
[2025-11-28T07:55:37.341+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 68d0d8c522fe, 36705, None)
[2025-11-28T07:55:37.379+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251128075537-0002/0 is now RUNNING
[2025-11-28T07:55:37.909+0000] {subprocess.py:106} INFO - 25/11/28 07:55:37 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-11-28T07:55:38.446+0000] {subprocess.py:106} INFO - 25/11/28 07:55:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-11-28T07:55:38.451+0000] {subprocess.py:106} INFO - 25/11/28 07:55:38 INFO SharedState: Warehouse path is 'file:/opt/spark/work-dir/spark-warehouse'.
[2025-11-28T07:55:44.713+0000] {subprocess.py:106} INFO - 25/11/28 07:55:44 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.30.0.7:43506) with ID 0,  ResourceProfileId 0
[2025-11-28T07:55:44.923+0000] {subprocess.py:106} INFO - 25/11/28 07:55:44 INFO BlockManagerMasterEndpoint: Registering block manager 172.30.0.7:45999 with 434.4 MiB RAM, BlockManagerId(0, 172.30.0.7, 45999, None)
[2025-11-28T07:55:45.441+0000] {subprocess.py:106} INFO - 25/11/28 07:55:45 INFO HiveConf: Found configuration file null
[2025-11-28T07:55:45.847+0000] {subprocess.py:106} INFO - 25/11/28 07:55:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
[2025-11-28T07:55:45.916+0000] {subprocess.py:106} INFO - 25/11/28 07:55:45 INFO metastore: Opened a connection to metastore, current connections: 1
[2025-11-28T07:55:45.966+0000] {subprocess.py:106} INFO - 25/11/28 07:55:45 INFO metastore: Connected to metastore.
[2025-11-28T07:55:46.590+0000] {subprocess.py:106} INFO - Dropping existing GOLD tables...
[2025-11-28T07:55:46.841+0000] {subprocess.py:106} INFO - 25/11/28 07:55:46 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/fact_job_posting/metadata/00000-7a99383c-cf4b-4d9a-9431-f9309d357f3c.metadata.json
[2025-11-28T07:55:48.073+0000] {subprocess.py:106} INFO - 25/11/28 07:55:48 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.fact_job_posting
[2025-11-28T07:55:52.101+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO HiveCatalog: Dropped table: gold.fact_job_posting
[2025-11-28T07:55:52.166+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_skill/metadata/00000-fbb3eacc-b5d4-4916-b0ef-2ecca57a62df.metadata.json
[2025-11-28T07:55:52.251+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.dim_skill
[2025-11-28T07:55:52.368+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO HiveCatalog: Dropped table: gold.dim_skill
[2025-11-28T07:55:52.417+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_location/metadata/00000-a89548c5-79b8-4448-a70d-96956d3e9828.metadata.json
[2025-11-28T07:55:52.493+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.dim_location
[2025-11-28T07:55:52.553+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO HiveCatalog: Dropped table: gold.dim_location
[2025-11-28T07:55:52.597+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_company/metadata/00000-82b40479-1bd3-492a-a69c-b4516f3d011e.metadata.json
[2025-11-28T07:55:52.669+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.dim_company
[2025-11-28T07:55:52.731+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO HiveCatalog: Dropped table: gold.dim_company
[2025-11-28T07:55:52.785+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_date/metadata/00000-5f530fd7-1943-4f30-a786-83358d373589.metadata.json
[2025-11-28T07:55:52.871+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.dim_date
[2025-11-28T07:55:52.932+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO HiveCatalog: Dropped table: gold.dim_date
[2025-11-28T07:55:52.985+0000] {subprocess.py:106} INFO - 25/11/28 07:55:52 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_job_category/metadata/00000-7937e705-b447-4778-8ffd-4720b2fe3c69.metadata.json
[2025-11-28T07:55:53.070+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.dim_job_category
[2025-11-28T07:55:53.139+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO HiveCatalog: Dropped table: gold.dim_job_category
[2025-11-28T07:55:53.179+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_work_mode/metadata/00000-2df30bcd-ba77-4c5e-9f08-2d6e993ee81d.metadata.json
[2025-11-28T07:55:53.264+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.gold.dim_work_mode
[2025-11-28T07:55:53.348+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO HiveCatalog: Dropped table: gold.dim_work_mode
[2025-11-28T07:55:53.350+0000] {subprocess.py:106} INFO - All GOLD tables dropped. Rebuilding...
[2025-11-28T07:55:53.402+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO BaseMetastoreTableOperations: Refreshing table metadata from new version: hdfs://dinhhoa-master:9000/user/ndh/warehouse/silver.db/it_jobs_clean/metadata/00031-42c3ca70-df6b-4157-aa8d-b02357878449.metadata.json
[2025-11-28T07:55:53.450+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO BaseMetastoreCatalog: Table loaded by catalog: hive_catalog.silver.it_jobs_clean
[2025-11-28T07:55:53.952+0000] {subprocess.py:106} INFO - 25/11/28 07:55:53 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter true
[2025-11-28T07:55:54.254+0000] {subprocess.py:106} INFO - 25/11/28 07:55:54 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:55:54.443+0000] {subprocess.py:106} INFO - 25/11/28 07:55:54 INFO V2ScanRelationPushDown:
[2025-11-28T07:55:54.444+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:55:54.445+0000] {subprocess.py:106} INFO - Pushed Aggregate Functions:
[2025-11-28T07:55:54.446+0000] {subprocess.py:106} INFO -  COUNT(*)
[2025-11-28T07:55:54.447+0000] {subprocess.py:106} INFO - Pushed Group by:
[2025-11-28T07:55:54.448+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:55:54.449+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:55:55.849+0000] {subprocess.py:106} INFO - 25/11/28 07:55:55 INFO CodeGenerator: Code generated in 565.933037 ms
[2025-11-28T07:55:55.933+0000] {subprocess.py:106} INFO - 25/11/28 07:55:55 INFO CodeGenerator: Code generated in 35.299293 ms
[2025-11-28T07:55:56.197+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Registering RDD 2 (count at <unknown>:0) as input to shuffle 0
[2025-11-28T07:55:56.209+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Got map stage job 0 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:55:56.211+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at <unknown>:0)
[2025-11-28T07:55:56.212+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:55:56.217+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:55:56.228+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:55:56.413+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.6 KiB, free 434.4 MiB)
[2025-11-28T07:55:56.463+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
[2025-11-28T07:55:56.469+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 68d0d8c522fe:36705 (size: 6.2 KiB, free: 434.4 MiB)
[2025-11-28T07:55:56.477+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:55:56.504+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:55:56.507+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-11-28T07:55:56.563+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.30.0.7, executor 0, partition 0, PROCESS_LOCAL, 9492 bytes)
[2025-11-28T07:55:56.924+0000] {subprocess.py:106} INFO - 25/11/28 07:55:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.30.0.7:45999 (size: 6.2 KiB, free: 434.4 MiB)
[2025-11-28T07:55:58.060+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1522 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:55:58.064+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-11-28T07:55:58.075+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: ShuffleMapStage 0 (count at <unknown>:0) finished in 1.815 s
[2025-11-28T07:55:58.076+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:55:58.078+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: running: Set()
[2025-11-28T07:55:58.080+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:55:58.081+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: failed: Set()
[2025-11-28T07:55:58.200+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO CodeGenerator: Code generated in 34.383285 ms
[2025-11-28T07:55:58.279+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO SparkContext: Starting job: count at <unknown>:0
[2025-11-28T07:55:58.287+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Got job 1 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:55:58.288+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Final stage: ResultStage 2 (count at <unknown>:0)
[2025-11-28T07:55:58.290+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-11-28T07:55:58.293+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:55:58.298+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:55:58.315+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.7 KiB, free 434.4 MiB)
[2025-11-28T07:55:58.322+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
[2025-11-28T07:55:58.323+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 68d0d8c522fe:36705 (size: 6.4 KiB, free: 434.4 MiB)
[2025-11-28T07:55:58.325+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:55:58.328+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:55:58.329+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-11-28T07:55:58.340+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:55:58.380+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.30.0.7:45999 (size: 6.4 KiB, free: 434.4 MiB)
[2025-11-28T07:55:58.501+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.30.0.7:43506
[2025-11-28T07:55:58.729+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 389 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:55:58.730+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-11-28T07:55:58.731+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: ResultStage 2 (count at <unknown>:0) finished in 0.417 s
[2025-11-28T07:55:58.742+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:55:58.743+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-11-28T07:55:58.745+0000] {subprocess.py:106} INFO - 25/11/28 07:55:58 INFO DAGScheduler: Job 1 finished: count at <unknown>:0, took 0.460527 s
[2025-11-28T07:55:58.767+0000] {subprocess.py:106} INFO -  Silver record count: 4829
[2025-11-28T07:56:00.354+0000] {subprocess.py:106} INFO - 25/11/28 07:56:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 68d0d8c522fe:36705 in memory (size: 6.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:00.364+0000] {subprocess.py:106} INFO - 25/11/28 07:56:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.30.0.7:45999 in memory (size: 6.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:01.288+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 68d0d8c522fe:36705 in memory (size: 6.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:01.289+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.30.0.7:45999 in memory (size: 6.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:01.311+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:01.335+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:01.608+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:01.609+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:01.610+0000] {subprocess.py:106} INFO - Pushed Filters: skills_required IS NOT NULL
[2025-11-28T07:56:01.611+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(skills_required#3),(size(skills_required#3, true) > 0)
[2025-11-28T07:56:01.612+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:01.679+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:01.680+0000] {subprocess.py:106} INFO - Output: skills_required#3
[2025-11-28T07:56:01.681+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:01.691+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter skills_required IS NOT NULL
[2025-11-28T07:56:01.719+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:01.869+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:01.915+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO SparkWrite: Requesting 0 bytes advisory partition size for table gold.dim_skill
[2025-11-28T07:56:01.916+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table gold.dim_skill
[2025-11-28T07:56:01.921+0000] {subprocess.py:106} INFO - 25/11/28 07:56:01 INFO SparkWrite: Requesting [] as write ordering for table gold.dim_skill
[2025-11-28T07:56:02.019+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 32.0 KiB, free 434.4 MiB)
[2025-11-28T07:56:02.048+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.3 MiB)
[2025-11-28T07:56:02.051+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:02.055+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO SparkContext: Created broadcast 2 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:02.104+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
[2025-11-28T07:56:02.112+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.3 MiB)
[2025-11-28T07:56:02.114+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:02.116+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO SparkContext: Created broadcast 3 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:02.443+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO CodeGenerator: Code generated in 146.145077 ms
[2025-11-28T07:56:02.597+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Registering RDD 9 (create at <unknown>:0) as input to shuffle 1
[2025-11-28T07:56:02.599+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Got map stage job 2 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:02.600+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (create at <unknown>:0)
[2025-11-28T07:56:02.601+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:02.602+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:02.603+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:02.616+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 39.8 KiB, free 434.2 MiB)
[2025-11-28T07:56:02.652+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:02.653+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 68d0d8c522fe:36705 (size: 17.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:02.656+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:02.662+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:02.663+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-11-28T07:56:02.689+0000] {subprocess.py:106} INFO - 25/11/28 07:56:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.30.0.7, executor 0, partition 0, ANY, 14536 bytes)
[2025-11-28T07:56:03.347+0000] {subprocess.py:106} INFO - 25/11/28 07:56:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.30.0.7:45999 (size: 17.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:04.029+0000] {subprocess.py:106} INFO - 25/11/28 07:56:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:06.457+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 3797 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:06.459+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-11-28T07:56:06.460+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: ShuffleMapStage 3 (create at <unknown>:0) finished in 3.852 s
[2025-11-28T07:56:06.461+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:06.463+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:06.463+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:06.464+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:06.484+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:06.638+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO CodeGenerator: Code generated in 69.446618 ms
[2025-11-28T07:56:06.695+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:06.738+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:06.754+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 68d0d8c522fe:36705 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:06.765+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 68d0d8c522fe:36705 in memory (size: 17.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:06.766+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO SparkContext: Created broadcast 5 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:06.768+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.dim_skill, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:06.787+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.30.0.7:45999 in memory (size: 17.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:06.789+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:06.797+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: Got job 3 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:06.799+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: Final stage: ResultStage 5 (create at <unknown>:0)
[2025-11-28T07:56:06.801+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-11-28T07:56:06.816+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:06.817+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:06.891+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 49.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:06.893+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 434.1 MiB)
[2025-11-28T07:56:06.906+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 68d0d8c522fe:36705 (size: 22.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:06.908+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:06.911+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:06.912+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-11-28T07:56:06.917+0000] {subprocess.py:106} INFO - 25/11/28 07:56:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:07.005+0000] {subprocess.py:106} INFO - 25/11/28 07:56:07 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.30.0.7:45999 (size: 22.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:07.188+0000] {subprocess.py:106} INFO - 25/11/28 07:56:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.30.0.7:43506
[2025-11-28T07:56:07.402+0000] {subprocess.py:106} INFO - 25/11/28 07:56:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.30.0.7:45999 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:08.317+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 1399 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:08.322+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-11-28T07:56:08.327+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO DAGScheduler: ResultStage 5 (create at <unknown>:0) finished in 1.438 s
[2025-11-28T07:56:08.329+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:08.331+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-11-28T07:56:08.336+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO DAGScheduler: Job 3 finished: create at <unknown>:0, took 1.543047 s
[2025-11-28T07:56:08.339+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_skill, format=PARQUET) is committing.
[2025-11-28T07:56:08.391+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO SparkWrite: Committing append with 1 new data files to table gold.dim_skill
[2025-11-28T07:56:08.951+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO SnapshotProducer: Committed snapshot 8611095577371906555 (MergeAppend)
[2025-11-28T07:56:09.000+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.dim_skill, snapshotId=8611095577371906555, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.59225262S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=410}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=410}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=7160}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=7160}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:09.002+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO SparkWrite: Committed in 607 ms
[2025-11-28T07:56:09.002+0000] {subprocess.py:106} INFO - 25/11/28 07:56:08 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_skill, format=PARQUET) committed.
[2025-11-28T07:56:09.973+0000] {subprocess.py:106} INFO - 25/11/28 07:56:09 INFO HiveTableOperations: Committed to table hive_catalog.gold.dim_skill with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_skill/metadata/00000-a3d00bcb-b366-46f4-bc53-333994f4dd47.metadata.json
[2025-11-28T07:56:09.975+0000] {subprocess.py:106} INFO - 25/11/28 07:56:09 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.dim_skill in 965 ms
[2025-11-28T07:56:10.241+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:10.252+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:10.304+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:10.306+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:10.307+0000] {subprocess.py:106} INFO - Pushed Filters: location IS NOT NULL
[2025-11-28T07:56:10.307+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(location#2)
[2025-11-28T07:56:10.308+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:10.310+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:10.311+0000] {subprocess.py:106} INFO - Output: location#2
[2025-11-28T07:56:10.311+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:10.313+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter location IS NOT NULL
[2025-11-28T07:56:10.316+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:10.491+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:10.495+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkWrite: Requesting 0 bytes advisory partition size for table gold.dim_location
[2025-11-28T07:56:10.499+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table gold.dim_location
[2025-11-28T07:56:10.506+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkWrite: Requesting [] as write ordering for table gold.dim_location
[2025-11-28T07:56:10.507+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 68d0d8c522fe:36705 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.522+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.30.0.7:45999 in memory (size: 22.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.523+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:10.580+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:10.587+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.597+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkContext: Created broadcast 7 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:10.599+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 68d0d8c522fe:36705 in memory (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.602+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.30.0.7:45999 in memory (size: 29.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:10.616+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:10.624+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:10.626+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.628+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkContext: Created broadcast 8 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:10.680+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.704+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.709+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.30.0.7:45999 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:10.810+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO CodeGenerator: Code generated in 70.357854 ms
[2025-11-28T07:56:10.833+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Registering RDD 15 (create at <unknown>:0) as input to shuffle 2
[2025-11-28T07:56:10.835+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Got map stage job 4 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:10.836+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (create at <unknown>:0)
[2025-11-28T07:56:10.837+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:10.838+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:10.839+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:10.846+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 38.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:10.866+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 434.2 MiB)
[2025-11-28T07:56:10.871+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 68d0d8c522fe:36705 (size: 16.7 KiB, free: 434.3 MiB)
[2025-11-28T07:56:10.875+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:10.878+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:10.883+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-11-28T07:56:10.886+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.30.0.7, executor 0, partition 0, ANY, 14455 bytes)
[2025-11-28T07:56:10.914+0000] {subprocess.py:106} INFO - 25/11/28 07:56:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.30.0.7:45999 (size: 16.7 KiB, free: 434.4 MiB)
[2025-11-28T07:56:11.085+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:11.695+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 817 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:11.698+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-11-28T07:56:11.701+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: ShuffleMapStage 6 (create at <unknown>:0) finished in 0.855 s
[2025-11-28T07:56:11.702+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:11.703+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:11.704+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:11.705+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:11.710+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:11.784+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO CodeGenerator: Code generated in 47.927046 ms
[2025-11-28T07:56:11.801+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:11.826+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:11.827+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 68d0d8c522fe:36705 in memory (size: 16.7 KiB, free: 434.3 MiB)
[2025-11-28T07:56:11.828+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 68d0d8c522fe:36705 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:11.830+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO SparkContext: Created broadcast 10 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:11.831+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.dim_location, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:11.835+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:11.837+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.30.0.7:45999 in memory (size: 16.7 KiB, free: 434.4 MiB)
[2025-11-28T07:56:11.838+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: Got job 5 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:11.839+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: Final stage: ResultStage 8 (create at <unknown>:0)
[2025-11-28T07:56:11.840+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-11-28T07:56:11.842+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:11.852+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:11.861+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 48.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:11.865+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 21.3 KiB, free 434.2 MiB)
[2025-11-28T07:56:11.867+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 68d0d8c522fe:36705 (size: 21.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:11.869+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:11.872+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:11.873+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-11-28T07:56:11.876+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:11.921+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.30.0.7:45999 (size: 21.3 KiB, free: 434.4 MiB)
[2025-11-28T07:56:11.946+0000] {subprocess.py:106} INFO - 25/11/28 07:56:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.30.0.7:43506
[2025-11-28T07:56:12.106+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.30.0.7:45999 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:12.388+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 507 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:12.399+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-11-28T07:56:12.406+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO DAGScheduler: ResultStage 8 (create at <unknown>:0) finished in 0.533 s
[2025-11-28T07:56:12.414+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:12.417+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-11-28T07:56:12.423+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO DAGScheduler: Job 5 finished: create at <unknown>:0, took 0.558934 s
[2025-11-28T07:56:12.425+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_location, format=PARQUET) is committing.
[2025-11-28T07:56:12.427+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO SparkWrite: Committing append with 1 new data files to table gold.dim_location
[2025-11-28T07:56:12.752+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO SnapshotProducer: Committed snapshot 452912404523042575 (MergeAppend)
[2025-11-28T07:56:12.793+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.dim_location, snapshotId=452912404523042575, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.399116816S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=5}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=5}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=1371}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1371}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:12.795+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO SparkWrite: Committed in 400 ms
[2025-11-28T07:56:12.796+0000] {subprocess.py:106} INFO - 25/11/28 07:56:12 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_location, format=PARQUET) committed.
[2025-11-28T07:56:13.131+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO HiveTableOperations: Committed to table hive_catalog.gold.dim_location with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_location/metadata/00000-c9a143d1-8228-4a52-8990-812939c623da.metadata.json
[2025-11-28T07:56:13.133+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.dim_location in 337 ms
[2025-11-28T07:56:13.254+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:13.264+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:13.289+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:13.290+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:13.291+0000] {subprocess.py:106} INFO - Pushed Filters: company_name IS NOT NULL
[2025-11-28T07:56:13.292+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(company_name#1)
[2025-11-28T07:56:13.292+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:13.293+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:13.294+0000] {subprocess.py:106} INFO - Output: company_name#1
[2025-11-28T07:56:13.295+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:13.295+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter company_name IS NOT NULL
[2025-11-28T07:56:13.296+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:13.334+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:13.335+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table gold.dim_company
[2025-11-28T07:56:13.336+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table gold.dim_company
[2025-11-28T07:56:13.339+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkWrite: Requesting [] as write ordering for table gold.dim_company
[2025-11-28T07:56:13.351+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:13.368+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:13.373+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.374+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.378+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkContext: Created broadcast 12 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:13.380+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.30.0.7:45999 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:13.400+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.30.0.7:45999 in memory (size: 29.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:13.401+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:13.408+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:13.410+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.411+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkContext: Created broadcast 13 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:13.411+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 68d0d8c522fe:36705 in memory (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.429+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.479+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.30.0.7:45999 in memory (size: 21.3 KiB, free: 434.4 MiB)
[2025-11-28T07:56:13.481+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 68d0d8c522fe:36705 in memory (size: 21.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.551+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO CodeGenerator: Code generated in 59.84657 ms
[2025-11-28T07:56:13.572+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Registering RDD 21 (create at <unknown>:0) as input to shuffle 3
[2025-11-28T07:56:13.573+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Got map stage job 6 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:13.574+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (create at <unknown>:0)
[2025-11-28T07:56:13.577+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:13.578+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:13.579+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[21] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:13.584+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 37.1 KiB, free 434.2 MiB)
[2025-11-28T07:56:13.602+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 434.2 MiB)
[2025-11-28T07:56:13.605+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 68d0d8c522fe:36705 (size: 16.2 KiB, free: 434.3 MiB)
[2025-11-28T07:56:13.606+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:13.607+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[21] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:13.609+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-11-28T07:56:13.613+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.30.0.7, executor 0, partition 0, ANY, 14463 bytes)
[2025-11-28T07:56:13.651+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.30.0.7:45999 (size: 16.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:13.804+0000] {subprocess.py:106} INFO - 25/11/28 07:56:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:14.079+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 468 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:14.084+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-11-28T07:56:14.086+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: ShuffleMapStage 9 (create at <unknown>:0) finished in 0.503 s
[2025-11-28T07:56:14.087+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:14.088+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:14.088+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:14.089+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:14.094+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:14.170+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO CodeGenerator: Code generated in 56.646991 ms
[2025-11-28T07:56:14.189+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:14.218+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:14.224+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 68d0d8c522fe:36705 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:14.226+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 68d0d8c522fe:36705 in memory (size: 16.2 KiB, free: 434.3 MiB)
[2025-11-28T07:56:14.234+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO SparkContext: Created broadcast 15 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:14.235+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.dim_company, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:14.237+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:14.240+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Got job 7 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:14.242+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Final stage: ResultStage 11 (create at <unknown>:0)
[2025-11-28T07:56:14.244+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-11-28T07:56:14.247+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:14.249+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[23] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:14.256+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.30.0.7:45999 in memory (size: 16.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:14.263+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 44.1 KiB, free 434.2 MiB)
[2025-11-28T07:56:14.269+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:14.272+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 68d0d8c522fe:36705 (size: 20.0 KiB, free: 434.3 MiB)
[2025-11-28T07:56:14.277+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:14.279+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:14.280+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-11-28T07:56:14.284+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:14.347+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.30.0.7:45999 (size: 20.0 KiB, free: 434.4 MiB)
[2025-11-28T07:56:14.385+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.30.0.7:43506
[2025-11-28T07:56:14.542+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.30.0.7:45999 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:14.884+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 597 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:14.893+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-11-28T07:56:14.897+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: ResultStage 11 (create at <unknown>:0) finished in 0.628 s
[2025-11-28T07:56:14.900+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:14.902+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-11-28T07:56:14.904+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO DAGScheduler: Job 7 finished: create at <unknown>:0, took 0.660157 s
[2025-11-28T07:56:14.909+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_company, format=PARQUET) is committing.
[2025-11-28T07:56:14.910+0000] {subprocess.py:106} INFO - 25/11/28 07:56:14 INFO SparkWrite: Committing append with 1 new data files to table gold.dim_company
[2025-11-28T07:56:15.655+0000] {subprocess.py:106} INFO - 25/11/28 07:56:15 INFO SnapshotProducer: Committed snapshot 3717784438639228452 (MergeAppend)
[2025-11-28T07:56:15.750+0000] {subprocess.py:106} INFO - 25/11/28 07:56:15 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.dim_company, snapshotId=3717784438639228452, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.853347972S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=721}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=721}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=14125}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=14125}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:15.756+0000] {subprocess.py:106} INFO - 25/11/28 07:56:15 INFO SparkWrite: Committed in 856 ms
[2025-11-28T07:56:15.761+0000] {subprocess.py:106} INFO - 25/11/28 07:56:15 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_company, format=PARQUET) committed.
[2025-11-28T07:56:16.544+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO HiveTableOperations: Committed to table hive_catalog.gold.dim_company with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_company/metadata/00000-368d4597-5739-48e5-a005-8ab6c55a1c8c.metadata.json
[2025-11-28T07:56:16.545+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.dim_company in 798 ms
[2025-11-28T07:56:16.901+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:16.910+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:16.956+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:16.958+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:16.959+0000] {subprocess.py:106} INFO - Pushed Filters:
[2025-11-28T07:56:16.959+0000] {subprocess.py:106} INFO - Post-Scan Filters: atleastnnonnulls(1, date_posted#4)
[2025-11-28T07:56:16.960+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:16.961+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:16.962+0000] {subprocess.py:106} INFO - Output: date_posted#4
[2025-11-28T07:56:16.963+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:16.964+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter true
[2025-11-28T07:56:16.965+0000] {subprocess.py:106} INFO - 25/11/28 07:56:16 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:17.002+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:17.004+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkWrite: Requesting 0 bytes advisory partition size for table gold.dim_date
[2025-11-28T07:56:17.005+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table gold.dim_date
[2025-11-28T07:56:17.006+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkWrite: Requesting [] as write ordering for table gold.dim_date
[2025-11-28T07:56:17.029+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:17.050+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:17.051+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.056+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkContext: Created broadcast 17 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:17.059+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.060+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.30.0.7:45999 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:17.079+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:17.090+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.30.0.7:45999 in memory (size: 29.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:17.091+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 68d0d8c522fe:36705 in memory (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.103+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:17.109+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.119+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkContext: Created broadcast 18 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:17.124+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 68d0d8c522fe:36705 in memory (size: 20.0 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.127+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.30.0.7:45999 in memory (size: 20.0 KiB, free: 434.4 MiB)
[2025-11-28T07:56:17.173+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.327+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO CodeGenerator: Code generated in 37.919631 ms
[2025-11-28T07:56:17.381+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Registering RDD 28 (create at <unknown>:0) as input to shuffle 4
[2025-11-28T07:56:17.382+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Got map stage job 8 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:17.383+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (create at <unknown>:0)
[2025-11-28T07:56:17.384+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:17.386+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:17.388+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[28] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:17.424+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 43.3 KiB, free 434.2 MiB)
[2025-11-28T07:56:17.452+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.2 KiB, free 434.2 MiB)
[2025-11-28T07:56:17.454+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 68d0d8c522fe:36705 (size: 18.2 KiB, free: 434.3 MiB)
[2025-11-28T07:56:17.458+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:17.460+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[28] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:17.461+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-11-28T07:56:17.464+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (172.30.0.7, executor 0, partition 0, ANY, 14181 bytes)
[2025-11-28T07:56:17.506+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.30.0.7:45999 (size: 18.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:17.773+0000] {subprocess.py:106} INFO - 25/11/28 07:56:17 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:18.346+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 887 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:18.347+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-11-28T07:56:18.348+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: ShuffleMapStage 12 (create at <unknown>:0) finished in 0.957 s
[2025-11-28T07:56:18.349+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:18.350+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:18.351+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:18.353+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:18.357+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:18.398+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO CodeGenerator: Code generated in 13.984152 ms
[2025-11-28T07:56:18.423+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:18.450+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:18.453+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 68d0d8c522fe:36705 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:18.457+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO SparkContext: Created broadcast 20 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:18.459+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.dim_date, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:18.461+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.30.0.7:45999 in memory (size: 18.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:18.462+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 68d0d8c522fe:36705 in memory (size: 18.2 KiB, free: 434.3 MiB)
[2025-11-28T07:56:18.465+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:18.467+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: Got job 9 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:18.468+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: Final stage: ResultStage 14 (create at <unknown>:0)
[2025-11-28T07:56:18.469+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-11-28T07:56:18.477+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:18.489+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[31] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:18.509+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 49.8 KiB, free 434.2 MiB)
[2025-11-28T07:56:18.514+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 434.1 MiB)
[2025-11-28T07:56:18.515+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 68d0d8c522fe:36705 (size: 21.2 KiB, free: 434.3 MiB)
[2025-11-28T07:56:18.521+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:18.522+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[31] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:18.524+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-11-28T07:56:18.525+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 9) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:18.573+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.30.0.7:45999 (size: 21.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:18.596+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.30.0.7:43506
[2025-11-28T07:56:18.957+0000] {subprocess.py:106} INFO - 25/11/28 07:56:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.30.0.7:45999 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:19.153+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 9) in 632 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:19.162+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-11-28T07:56:19.163+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO DAGScheduler: ResultStage 14 (create at <unknown>:0) finished in 0.665 s
[2025-11-28T07:56:19.167+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:19.172+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-11-28T07:56:19.173+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO DAGScheduler: Job 9 finished: create at <unknown>:0, took 0.689939 s
[2025-11-28T07:56:19.174+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_date, format=PARQUET) is committing.
[2025-11-28T07:56:19.175+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO SparkWrite: Committing append with 1 new data files to table gold.dim_date
[2025-11-28T07:56:19.995+0000] {subprocess.py:106} INFO - 25/11/28 07:56:19 INFO SnapshotProducer: Committed snapshot 2646821726532575016 (MergeAppend)
[2025-11-28T07:56:20.052+0000] {subprocess.py:106} INFO - 25/11/28 07:56:20 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.dim_date, snapshotId=2646821726532575016, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.893888689S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=67}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=67}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=2905}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=2905}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:20.053+0000] {subprocess.py:106} INFO - 25/11/28 07:56:20 INFO SparkWrite: Committed in 895 ms
[2025-11-28T07:56:20.055+0000] {subprocess.py:106} INFO - 25/11/28 07:56:20 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_date, format=PARQUET) committed.
[2025-11-28T07:56:20.757+0000] {subprocess.py:106} INFO - 25/11/28 07:56:20 INFO HiveTableOperations: Committed to table hive_catalog.gold.dim_date with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_date/metadata/00000-bbf07799-5374-4c7c-9e7f-4e6b4b401298.metadata.json
[2025-11-28T07:56:20.758+0000] {subprocess.py:106} INFO - 25/11/28 07:56:20 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.dim_date in 705 ms
[2025-11-28T07:56:21.001+0000] {subprocess.py:106} INFO - 25/11/28 07:56:20 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:21.011+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:21.058+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:21.059+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:21.062+0000] {subprocess.py:106} INFO - Pushed Filters:
[2025-11-28T07:56:21.062+0000] {subprocess.py:106} INFO - Post-Scan Filters: atleastnnonnulls(1, job_category#6)
[2025-11-28T07:56:21.063+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:21.064+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:21.064+0000] {subprocess.py:106} INFO - Output: job_category#6
[2025-11-28T07:56:21.065+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:21.066+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter true
[2025-11-28T07:56:21.066+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:21.108+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:21.110+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkWrite: Requesting 0 bytes advisory partition size for table gold.dim_job_category
[2025-11-28T07:56:21.111+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table gold.dim_job_category
[2025-11-28T07:56:21.111+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkWrite: Requesting [] as write ordering for table gold.dim_job_category
[2025-11-28T07:56:21.132+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:21.156+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:21.158+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.160+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkContext: Created broadcast 22 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:21.166+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.190+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.30.0.7:45999 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:21.195+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.200+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:21.201+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:21.205+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.206+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkContext: Created broadcast 23 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:21.219+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 68d0d8c522fe:36705 in memory (size: 21.2 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.223+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.30.0.7:45999 in memory (size: 21.2 KiB, free: 434.4 MiB)
[2025-11-28T07:56:21.258+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 68d0d8c522fe:36705 in memory (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.268+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.30.0.7:45999 in memory (size: 29.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:21.327+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO CodeGenerator: Code generated in 27.442222 ms
[2025-11-28T07:56:21.352+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Registering RDD 36 (create at <unknown>:0) as input to shuffle 5
[2025-11-28T07:56:21.354+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Got map stage job 10 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:21.355+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (create at <unknown>:0)
[2025-11-28T07:56:21.356+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:21.359+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:21.361+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[36] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:21.365+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 38.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:21.381+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
[2025-11-28T07:56:21.385+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 68d0d8c522fe:36705 (size: 16.5 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.386+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:21.387+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[36] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:21.388+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-11-28T07:56:21.389+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 10) (172.30.0.7, executor 0, partition 0, ANY, 14184 bytes)
[2025-11-28T07:56:21.412+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.30.0.7:45999 (size: 16.5 KiB, free: 434.4 MiB)
[2025-11-28T07:56:21.538+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:21.875+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 10) in 486 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:21.877+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-11-28T07:56:21.882+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: ShuffleMapStage 15 (create at <unknown>:0) finished in 0.520 s
[2025-11-28T07:56:21.884+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:21.886+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:21.888+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:21.890+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:21.906+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:21.944+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:21.945+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.2 MiB)
[2025-11-28T07:56:21.949+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 68d0d8c522fe:36705 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:21.950+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkContext: Created broadcast 25 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:21.952+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.dim_job_category, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:21.954+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:21.955+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Got job 11 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:21.956+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Final stage: ResultStage 17 (create at <unknown>:0)
[2025-11-28T07:56:21.956+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2025-11-28T07:56:21.959+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:21.964+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[39] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:21.977+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 40.5 KiB, free 434.1 MiB)
[2025-11-28T07:56:22.000+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:22.002+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 68d0d8c522fe:36705 (size: 19.0 KiB, free: 434.3 MiB)
[2025-11-28T07:56:22.003+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:22.004+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[39] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:22.005+0000] {subprocess.py:106} INFO - 25/11/28 07:56:21 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-11-28T07:56:22.017+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 11) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:22.020+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.30.0.7:45999 in memory (size: 16.5 KiB, free: 434.4 MiB)
[2025-11-28T07:56:22.021+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 68d0d8c522fe:36705 in memory (size: 16.5 KiB, free: 434.3 MiB)
[2025-11-28T07:56:22.070+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.30.0.7:45999 (size: 19.0 KiB, free: 434.4 MiB)
[2025-11-28T07:56:22.087+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.30.0.7:43506
[2025-11-28T07:56:22.201+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.30.0.7:45999 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:22.402+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 11) in 396 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:22.406+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-11-28T07:56:22.410+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO DAGScheduler: ResultStage 17 (create at <unknown>:0) finished in 0.433 s
[2025-11-28T07:56:22.411+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:22.412+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2025-11-28T07:56:22.412+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO DAGScheduler: Job 11 finished: create at <unknown>:0, took 0.453057 s
[2025-11-28T07:56:22.414+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_job_category, format=PARQUET) is committing.
[2025-11-28T07:56:22.415+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO SparkWrite: Committing append with 1 new data files to table gold.dim_job_category
[2025-11-28T07:56:22.683+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO SnapshotProducer: Committed snapshot 8545791022351515726 (MergeAppend)
[2025-11-28T07:56:22.730+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.dim_job_category, snapshotId=8545791022351515726, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.319469607S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=81}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=81}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=2855}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=2855}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:22.733+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO SparkWrite: Committed in 320 ms
[2025-11-28T07:56:22.734+0000] {subprocess.py:106} INFO - 25/11/28 07:56:22 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_job_category, format=PARQUET) committed.
[2025-11-28T07:56:23.035+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO HiveTableOperations: Committed to table hive_catalog.gold.dim_job_category with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_job_category/metadata/00000-dbb16006-2705-489c-a806-b36b1264517b.metadata.json
[2025-11-28T07:56:23.036+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.dim_job_category in 305 ms
[2025-11-28T07:56:23.116+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:23.126+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:23.145+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:23.146+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:23.147+0000] {subprocess.py:106} INFO - Pushed Filters:
[2025-11-28T07:56:23.147+0000] {subprocess.py:106} INFO - Post-Scan Filters: atleastnnonnulls(1, work_mode#7)
[2025-11-28T07:56:23.148+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:23.149+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:23.149+0000] {subprocess.py:106} INFO - Output: work_mode#7
[2025-11-28T07:56:23.150+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:23.151+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter true
[2025-11-28T07:56:23.151+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:23.184+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:23.185+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkWrite: Requesting 0 bytes advisory partition size for table gold.dim_work_mode
[2025-11-28T07:56:23.186+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table gold.dim_work_mode
[2025-11-28T07:56:23.187+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkWrite: Requesting [] as write ordering for table gold.dim_work_mode
[2025-11-28T07:56:23.197+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:23.201+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:23.202+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.203+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkContext: Created broadcast 27 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:23.226+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:23.249+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.0 MiB)
[2025-11-28T07:56:23.254+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:23.255+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.256+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkContext: Created broadcast 28 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:23.267+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 68d0d8c522fe:36705 in memory (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.274+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.30.0.7:45999 in memory (size: 29.4 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.291+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.30.0.7:45999 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.296+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.318+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 68d0d8c522fe:36705 in memory (size: 19.0 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.320+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.30.0.7:45999 in memory (size: 19.0 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.371+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO CodeGenerator: Code generated in 80.725437 ms
[2025-11-28T07:56:23.385+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Registering RDD 43 (create at <unknown>:0) as input to shuffle 6
[2025-11-28T07:56:23.386+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Got map stage job 12 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:23.387+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (create at <unknown>:0)
[2025-11-28T07:56:23.388+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:23.389+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:23.392+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[43] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:23.397+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 30.5 KiB, free 434.2 MiB)
[2025-11-28T07:56:23.398+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 434.2 MiB)
[2025-11-28T07:56:23.400+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 68d0d8c522fe:36705 (size: 12.8 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.402+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:23.403+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[43] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:23.405+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-11-28T07:56:23.408+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 12) (172.30.0.7, executor 0, partition 0, ANY, 14181 bytes)
[2025-11-28T07:56:23.429+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.30.0.7:45999 (size: 12.8 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.518+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.693+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 12) in 286 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:23.694+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-11-28T07:56:23.703+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: ShuffleMapStage 18 (create at <unknown>:0) finished in 0.301 s
[2025-11-28T07:56:23.706+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:23.714+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:23.715+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:23.716+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:23.748+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:23.820+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO CodeGenerator: Code generated in 45.843346 ms
[2025-11-28T07:56:23.836+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:23.869+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.2 MiB)
[2025-11-28T07:56:23.874+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 68d0d8c522fe:36705 (size: 29.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.876+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkContext: Created broadcast 30 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:23.878+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.dim_work_mode, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:23.883+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 68d0d8c522fe:36705 in memory (size: 12.8 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.887+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:23.891+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Got job 13 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:23.892+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Final stage: ResultStage 20 (create at <unknown>:0)
[2025-11-28T07:56:23.894+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-11-28T07:56:23.896+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:23.897+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.30.0.7:45999 in memory (size: 12.8 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.898+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[45] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:23.906+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 43.8 KiB, free 434.2 MiB)
[2025-11-28T07:56:23.913+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:23.916+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 68d0d8c522fe:36705 (size: 19.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:23.919+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:23.920+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[45] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:23.922+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-11-28T07:56:23.924+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 13) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:23.947+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.30.0.7:45999 (size: 19.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:23.989+0000] {subprocess.py:106} INFO - 25/11/28 07:56:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.30.0.7:43506
[2025-11-28T07:56:24.055+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.30.0.7:45999 (size: 29.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:24.282+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 13) in 363 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:24.291+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-11-28T07:56:24.293+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO DAGScheduler: ResultStage 20 (create at <unknown>:0) finished in 0.390 s
[2025-11-28T07:56:24.295+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:24.299+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-11-28T07:56:24.300+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO DAGScheduler: Job 13 finished: create at <unknown>:0, took 0.418739 s
[2025-11-28T07:56:24.303+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_work_mode, format=PARQUET) is committing.
[2025-11-28T07:56:24.306+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO SparkWrite: Committing append with 1 new data files to table gold.dim_work_mode
[2025-11-28T07:56:24.577+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO SnapshotProducer: Committed snapshot 6458235084795476138 (MergeAppend)
[2025-11-28T07:56:24.614+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.dim_work_mode, snapshotId=6458235084795476138, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.315532551S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=3}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=3}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=731}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=731}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:24.616+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO SparkWrite: Committed in 316 ms
[2025-11-28T07:56:24.618+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.dim_work_mode, format=PARQUET) committed.
[2025-11-28T07:56:24.945+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO HiveTableOperations: Committed to table hive_catalog.gold.dim_work_mode with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/dim_work_mode/metadata/00000-d1e0dadd-0748-40c5-b902-3039291b6660.metadata.json
[2025-11-28T07:56:24.946+0000] {subprocess.py:106} INFO - 25/11/28 07:56:24 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.dim_work_mode in 331 ms
[2025-11-28T07:56:25.500+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BaseMetastoreCatalog: Table properties set at catalog level through catalog properties: {}
[2025-11-28T07:56:25.509+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BaseMetastoreCatalog: Table properties enforced at catalog level through catalog properties: {}
[2025-11-28T07:56:25.684+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:25.689+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.30.0.7:45999 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:25.698+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 68d0d8c522fe:36705 in memory (size: 29.3 KiB, free: 434.4 MiB)
[2025-11-28T07:56:25.706+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.30.0.7:45999 in memory (size: 29.3 KiB, free: 434.4 MiB)
[2025-11-28T07:56:25.716+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 68d0d8c522fe:36705 in memory (size: 19.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:25.723+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.30.0.7:45999 in memory (size: 19.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:25.732+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:25.784+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.785+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.786+0000] {subprocess.py:106} INFO - Pushed Filters: skills_required IS NOT NULL
[2025-11-28T07:56:25.788+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(skills_required#3),(size(skills_required#3, true) > 0)
[2025-11-28T07:56:25.790+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.791+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.792+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.793+0000] {subprocess.py:106} INFO - Pushed Filters: work_mode IS NOT NULL
[2025-11-28T07:56:25.794+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(work_mode#355),atleastnnonnulls(1, work_mode#355)
[2025-11-28T07:56:25.795+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.796+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.797+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.799+0000] {subprocess.py:106} INFO - Pushed Filters: skills_required IS NOT NULL
[2025-11-28T07:56:25.801+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(skills_required#384),(size(skills_required#384, true) > 0)
[2025-11-28T07:56:25.802+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.803+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.806+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.807+0000] {subprocess.py:106} INFO - Pushed Filters: location IS NOT NULL
[2025-11-28T07:56:25.809+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(location#437)
[2025-11-28T07:56:25.810+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.811+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.813+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.814+0000] {subprocess.py:106} INFO - Pushed Filters: company_name IS NOT NULL
[2025-11-28T07:56:25.815+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(company_name#498)
[2025-11-28T07:56:25.818+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.823+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.830+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.837+0000] {subprocess.py:106} INFO - Pushed Filters:
[2025-11-28T07:56:25.839+0000] {subprocess.py:106} INFO - Post-Scan Filters: atleastnnonnulls(1, date_posted#543)
[2025-11-28T07:56:25.841+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.848+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.851+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.853+0000] {subprocess.py:106} INFO - Pushed Filters:
[2025-11-28T07:56:25.856+0000] {subprocess.py:106} INFO - Post-Scan Filters: atleastnnonnulls(1, job_category#594),isnotnull(initcap(trim(job_category#594, None)))
[2025-11-28T07:56:25.858+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.859+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.862+0000] {subprocess.py:106} INFO - Output: job_title#0, company_name#1, location#2, skills_required#3, date_posted#4, job_link#5, job_category#6, work_mode#7, clean_time#12
[2025-11-28T07:56:25.863+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.864+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.865+0000] {subprocess.py:106} INFO - Output: work_mode#355
[2025-11-28T07:56:25.867+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.867+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.868+0000] {subprocess.py:106} INFO - Output: skills_required#384
[2025-11-28T07:56:25.869+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.870+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.871+0000] {subprocess.py:106} INFO - Output: location#437
[2025-11-28T07:56:25.871+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.872+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.873+0000] {subprocess.py:106} INFO - Output: company_name#498
[2025-11-28T07:56:25.874+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.875+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.876+0000] {subprocess.py:106} INFO - Output: date_posted#543
[2025-11-28T07:56:25.876+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.877+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:25.878+0000] {subprocess.py:106} INFO - Output: job_category#594
[2025-11-28T07:56:25.879+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:25.879+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter skills_required IS NOT NULL
[2025-11-28T07:56:25.880+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.914+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:25.916+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter work_mode IS NOT NULL
[2025-11-28T07:56:25.917+0000] {subprocess.py:106} INFO - 25/11/28 07:56:25 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.014+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.021+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter skills_required IS NOT NULL
[2025-11-28T07:56:26.022+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.095+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.100+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter location IS NOT NULL
[2025-11-28T07:56:26.101+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.193+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.201+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter company_name IS NOT NULL
[2025-11-28T07:56:26.203+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.291+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.292+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter true
[2025-11-28T07:56:26.293+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.362+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.364+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter true
[2025-11-28T07:56:26.365+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.407+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:26.417+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkWrite: Requesting 402653184 bytes advisory partition size for table gold.fact_job_posting
[2025-11-28T07:56:26.418+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkWrite: Requesting ClusteredDistribution(date_id) as write distribution for table gold.fact_job_posting
[2025-11-28T07:56:26.430+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkWrite: Requesting [] as write ordering for table gold.fact_job_posting
[2025-11-28T07:56:26.552+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 32.0 KiB, free 434.4 MiB)
[2025-11-28T07:56:26.555+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.3 MiB)
[2025-11-28T07:56:26.556+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:26.558+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 32 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.573+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
[2025-11-28T07:56:26.578+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.3 MiB)
[2025-11-28T07:56:26.579+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:26.580+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 33 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.595+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:26.623+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:26.624+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:26.625+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 34 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.642+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
[2025-11-28T07:56:26.645+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.2 MiB)
[2025-11-28T07:56:26.646+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:26.648+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 35 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.665+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:26.671+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.1 MiB)
[2025-11-28T07:56:26.672+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:26.674+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 36 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.711+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
[2025-11-28T07:56:26.715+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.0 MiB)
[2025-11-28T07:56:26.719+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:26.720+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 37 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.736+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 32.0 KiB, free 434.0 MiB)
[2025-11-28T07:56:26.749+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 434.0 MiB)
[2025-11-28T07:56:26.751+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:26.751+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 38 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.771+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 32.0 KiB, free 433.9 MiB)
[2025-11-28T07:56:26.797+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)
[2025-11-28T07:56:26.802+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:26.806+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 39 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.813+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 32.0 KiB, free 433.9 MiB)
[2025-11-28T07:56:26.817+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.9 MiB)
[2025-11-28T07:56:26.819+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.1 MiB)
[2025-11-28T07:56:26.821+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 40 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.836+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 32.0 KiB, free 433.8 MiB)
[2025-11-28T07:56:26.838+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.8 MiB)
[2025-11-28T07:56:26.839+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.1 MiB)
[2025-11-28T07:56:26.842+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 41 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.856+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 32.0 KiB, free 433.8 MiB)
[2025-11-28T07:56:26.863+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.7 MiB)
[2025-11-28T07:56:26.885+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.1 MiB)
[2025-11-28T07:56:26.887+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 42 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.901+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 32.0 KiB, free 433.7 MiB)
[2025-11-28T07:56:26.904+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.7 MiB)
[2025-11-28T07:56:26.906+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.0 MiB)
[2025-11-28T07:56:26.908+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 43 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.921+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-11-28T07:56:26.924+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.6 MiB)
[2025-11-28T07:56:26.926+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.0 MiB)
[2025-11-28T07:56:26.930+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 44 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:26.943+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-11-28T07:56:26.963+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.6 MiB)
[2025-11-28T07:56:26.970+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 434.0 MiB)
[2025-11-28T07:56:26.971+0000] {subprocess.py:106} INFO - 25/11/28 07:56:26 INFO SparkContext: Created broadcast 45 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:27.240+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO CodeGenerator: Code generated in 51.532489 ms
[2025-11-28T07:56:27.254+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Registering RDD 49 (create at <unknown>:0) as input to shuffle 7
[2025-11-28T07:56:27.256+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Got map stage job 14 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:27.257+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Final stage: ShuffleMapStage 21 (create at <unknown>:0)
[2025-11-28T07:56:27.259+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:27.261+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:27.262+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[49] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:27.266+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 37.9 KiB, free 433.5 MiB)
[2025-11-28T07:56:27.298+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 433.5 MiB)
[2025-11-28T07:56:27.299+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 68d0d8c522fe:36705 (size: 16.6 KiB, free: 434.0 MiB)
[2025-11-28T07:56:27.300+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:27.303+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[49] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:27.306+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
[2025-11-28T07:56:27.311+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 14) (172.30.0.7, executor 0, partition 0, ANY, 14457 bytes)
[2025-11-28T07:56:27.348+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.30.0.7:45999 (size: 16.6 KiB, free: 434.4 MiB)
[2025-11-28T07:56:27.415+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO CodeGenerator: Code generated in 93.663223 ms
[2025-11-28T07:56:27.438+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Registering RDD 53 (create at <unknown>:0) as input to shuffle 8
[2025-11-28T07:56:27.442+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Got map stage job 15 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:27.443+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (create at <unknown>:0)
[2025-11-28T07:56:27.446+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:27.464+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:27.466+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[53] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:27.475+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 40.3 KiB, free 433.5 MiB)
[2025-11-28T07:56:27.483+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 433.4 MiB)
[2025-11-28T07:56:27.494+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 68d0d8c522fe:36705 (size: 17.6 KiB, free: 434.0 MiB)
[2025-11-28T07:56:27.498+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:27.500+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[53] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:27.501+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-11-28T07:56:27.517+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.4 MiB)
[2025-11-28T07:56:27.538+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO CodeGenerator: Code generated in 92.96878 ms
[2025-11-28T07:56:27.559+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Registering RDD 57 (create at <unknown>:0) as input to shuffle 9
[2025-11-28T07:56:27.561+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Got map stage job 16 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:27.562+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (create at <unknown>:0)
[2025-11-28T07:56:27.563+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:27.564+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:27.568+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[57] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:27.571+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 38.0 KiB, free 433.4 MiB)
[2025-11-28T07:56:27.595+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 433.4 MiB)
[2025-11-28T07:56:27.597+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 68d0d8c522fe:36705 (size: 16.7 KiB, free: 433.9 MiB)
[2025-11-28T07:56:27.602+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:27.606+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[57] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:27.607+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
[2025-11-28T07:56:27.696+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO CodeGenerator: Code generated in 101.264554 ms
[2025-11-28T07:56:27.721+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Registering RDD 61 (create at <unknown>:0) as input to shuffle 10
[2025-11-28T07:56:27.727+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Got map stage job 17 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:27.728+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (create at <unknown>:0)
[2025-11-28T07:56:27.731+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:27.733+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:27.734+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[61] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:27.761+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 37.2 KiB, free 433.4 MiB)
[2025-11-28T07:56:27.766+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 433.3 MiB)
[2025-11-28T07:56:27.767+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 68d0d8c522fe:36705 (size: 16.3 KiB, free: 433.9 MiB)
[2025-11-28T07:56:27.774+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:27.783+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[61] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:27.784+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-11-28T07:56:27.867+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO CodeGenerator: Code generated in 89.202805 ms
[2025-11-28T07:56:27.890+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Registering RDD 65 (create at <unknown>:0) as input to shuffle 11
[2025-11-28T07:56:27.895+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Got map stage job 18 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:27.898+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (create at <unknown>:0)
[2025-11-28T07:56:27.899+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:27.900+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:27.902+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[65] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:27.915+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 45.2 KiB, free 433.3 MiB)
[2025-11-28T07:56:27.955+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.3 MiB)
[2025-11-28T07:56:27.960+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 68d0d8c522fe:36705 (size: 19.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:27.962+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:27.970+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[65] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:27.972+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-11-28T07:56:27.991+0000] {subprocess.py:106} INFO - 25/11/28 07:56:27 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 15) (172.30.0.7, executor 0, partition 0, ANY, 14536 bytes)
[2025-11-28T07:56:28.016+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 14) in 708 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:28.019+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2025-11-28T07:56:28.032+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: ShuffleMapStage 21 (create at <unknown>:0) finished in 0.765 s
[2025-11-28T07:56:28.040+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:28.045+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: running: Set(ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 22, ShuffleMapStage 23)
[2025-11-28T07:56:28.047+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:28.048+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:28.106+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO CodeGenerator: Code generated in 197.478357 ms
[2025-11-28T07:56:28.127+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.30.0.7:45999 (size: 17.6 KiB, free: 434.3 MiB)
[2025-11-28T07:56:28.139+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Registering RDD 69 (create at <unknown>:0) as input to shuffle 12
[2025-11-28T07:56:28.142+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Got map stage job 19 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:28.144+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Final stage: ShuffleMapStage 26 (create at <unknown>:0)
[2025-11-28T07:56:28.146+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:28.148+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:28.149+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[69] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:28.150+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 39.6 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.159+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.162+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 68d0d8c522fe:36705 (size: 17.3 KiB, free: 433.9 MiB)
[2025-11-28T07:56:28.165+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:28.221+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[69] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:28.226+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
[2025-11-28T07:56:28.268+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 32.0 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.316+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.319+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:28.350+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO SparkContext: Created broadcast 52 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:28.354+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 68d0d8c522fe:36705 in memory (size: 16.6 KiB, free: 433.9 MiB)
[2025-11-28T07:56:28.355+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:28.362+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.30.0.7:45999 in memory (size: 16.6 KiB, free: 434.3 MiB)
[2025-11-28T07:56:28.492+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:28.616+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO CodeGenerator: Code generated in 56.935154 ms
[2025-11-28T07:56:28.663+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:28.672+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Got job 20 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:28.675+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Final stage: ResultStage 28 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:28.679+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
[2025-11-28T07:56:28.680+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:28.682+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[72] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:28.683+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 42.7 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.725+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.737+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 68d0d8c522fe:36705 (size: 18.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:28.740+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:28.741+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[72] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:28.745+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-11-28T07:56:28.746+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:28.754+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 16) (172.30.0.7, executor 0, partition 0, ANY, 14455 bytes)
[2025-11-28T07:56:28.755+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 15) in 764 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:28.756+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-11-28T07:56:28.763+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: ShuffleMapStage 22 (create at <unknown>:0) finished in 1.297 s
[2025-11-28T07:56:28.770+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:28.771+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: running: Set(ShuffleMapStage 24, ResultStage 28, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 23)
[2025-11-28T07:56:28.772+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:28.778+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:28.828+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 32.0 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.831+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.2 MiB)
[2025-11-28T07:56:28.833+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:28.837+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO SparkContext: Created broadcast 54 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:28.910+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.30.0.7:45999 (size: 16.7 KiB, free: 434.3 MiB)
[2025-11-28T07:56:28.989+0000] {subprocess.py:106} INFO - 25/11/28 07:56:28 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:29.086+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.3 MiB)
[2025-11-28T07:56:29.340+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO CodeGenerator: Code generated in 139.059686 ms
[2025-11-28T07:56:29.500+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:29.502+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: Got job 21 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:29.505+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: Final stage: ResultStage 30 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:29.517+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-11-28T07:56:29.524+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:29.528+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:29.542+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 45.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:29.550+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 433.1 MiB)
[2025-11-28T07:56:29.555+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 68d0d8c522fe:36705 (size: 20.4 KiB, free: 433.8 MiB)
[2025-11-28T07:56:29.562+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:29.567+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:29.569+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-11-28T07:56:29.713+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 17) (172.30.0.7, executor 0, partition 0, ANY, 14463 bytes)
[2025-11-28T07:56:29.715+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 16) in 968 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:29.726+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2025-11-28T07:56:29.729+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: ShuffleMapStage 23 (create at <unknown>:0) finished in 2.151 s
[2025-11-28T07:56:29.731+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:29.734+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: running: Set(ResultStage 30, ShuffleMapStage 24, ResultStage 28, ShuffleMapStage 25, ShuffleMapStage 26)
[2025-11-28T07:56:29.736+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:29.738+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:29.756+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-11-28T07:56:29.770+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:29.771+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:29.774+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO SparkContext: Created broadcast 56 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:29.788+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.30.0.7:45999 (size: 16.3 KiB, free: 434.3 MiB)
[2025-11-28T07:56:29.827+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:29.901+0000] {subprocess.py:106} INFO - 25/11/28 07:56:29 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:30.010+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO CodeGenerator: Code generated in 74.803215 ms
[2025-11-28T07:56:30.079+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:30.084+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Got job 22 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:30.086+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Final stage: ResultStage 32 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:30.087+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-11-28T07:56:30.088+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:30.090+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[78] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:30.097+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 42.6 KiB, free 433.0 MiB)
[2025-11-28T07:56:30.124+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:30.129+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 68d0d8c522fe:36705 (size: 19.0 KiB, free: 433.8 MiB)
[2025-11-28T07:56:30.131+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 68d0d8c522fe:36705 in memory (size: 17.6 KiB, free: 433.8 MiB)
[2025-11-28T07:56:30.136+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:30.139+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[78] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:30.142+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-11-28T07:56:30.145+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.30.0.7:45999 in memory (size: 17.6 KiB, free: 434.3 MiB)
[2025-11-28T07:56:30.159+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:30.187+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 68d0d8c522fe:36705 in memory (size: 16.7 KiB, free: 433.9 MiB)
[2025-11-28T07:56:30.189+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.30.0.7:45999 in memory (size: 16.7 KiB, free: 434.3 MiB)
[2025-11-28T07:56:30.210+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:30.294+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 18) (172.30.0.7, executor 0, partition 0, ANY, 14181 bytes)
[2025-11-28T07:56:30.310+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 17) in 594 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:30.311+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-11-28T07:56:30.312+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: ShuffleMapStage 24 (create at <unknown>:0) finished in 2.569 s
[2025-11-28T07:56:30.314+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:30.315+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: running: Set(ResultStage 30, ResultStage 32, ResultStage 28, ShuffleMapStage 25, ShuffleMapStage 26)
[2025-11-28T07:56:30.320+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:30.322+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:30.364+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 32.0 KiB, free 433.2 MiB)
[2025-11-28T07:56:30.372+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:30.380+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.30.0.7:45999 (size: 19.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:30.381+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:30.382+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Created broadcast 58 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:30.414+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:30.509+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO CodeGenerator: Code generated in 40.891967 ms
[2025-11-28T07:56:30.542+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:30.544+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Got job 23 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:30.545+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Final stage: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:30.546+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
[2025-11-28T07:56:30.547+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:30.548+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:30.559+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:30.561+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 42.2 KiB, free 433.1 MiB)
[2025-11-28T07:56:30.563+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 433.1 MiB)
[2025-11-28T07:56:30.567+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 68d0d8c522fe:36705 (size: 18.7 KiB, free: 433.8 MiB)
[2025-11-28T07:56:30.570+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:30.572+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:30.574+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
[2025-11-28T07:56:30.769+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 19) (172.30.0.7, executor 0, partition 0, ANY, 14184 bytes)
[2025-11-28T07:56:30.776+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 18) in 478 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:30.782+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-11-28T07:56:30.783+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: ShuffleMapStage 25 (create at <unknown>:0) finished in 2.879 s
[2025-11-28T07:56:30.786+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:30.787+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: running: Set(ResultStage 30, ResultStage 34, ResultStage 32, ResultStage 28, ShuffleMapStage 26)
[2025-11-28T07:56:30.791+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:30.794+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:30.801+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.30.0.7:45999 (size: 17.3 KiB, free: 434.2 MiB)
[2025-11-28T07:56:30.818+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:30.823+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:30.826+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:30.828+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Created broadcast 60 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:30.862+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:30.904+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-28T07:56:30.949+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:30.951+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO CodeGenerator: Code generated in 23.797533 ms
[2025-11-28T07:56:30.997+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:31.000+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Got job 24 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:31.001+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Final stage: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:31.002+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-11-28T07:56:31.004+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:31.005+0000] {subprocess.py:106} INFO - 25/11/28 07:56:30 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[84] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:31.008+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 45.4 KiB, free 433.0 MiB)
[2025-11-28T07:56:31.594+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 433.0 MiB)
[2025-11-28T07:56:31.612+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 68d0d8c522fe:36705 (size: 20.2 KiB, free: 433.8 MiB)
[2025-11-28T07:56:31.621+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 68d0d8c522fe:36705 in memory (size: 16.3 KiB, free: 433.8 MiB)
[2025-11-28T07:56:31.625+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:31.630+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[84] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:31.642+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-11-28T07:56:31.643+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.30.0.7:45999 in memory (size: 16.3 KiB, free: 434.2 MiB)
[2025-11-28T07:56:31.660+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 68d0d8c522fe:36705 in memory (size: 19.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:31.665+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.30.0.7:45999 in memory (size: 19.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:31.688+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:31.724+0000] {subprocess.py:106} INFO - 25/11/28 07:56:31 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:32.893+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 20) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:32.903+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 19) in 2125 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:32.905+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool
[2025-11-28T07:56:32.912+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO DAGScheduler: ShuffleMapStage 26 (create at <unknown>:0) finished in 4.749 s
[2025-11-28T07:56:32.931+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:32.946+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO DAGScheduler: running: Set(ResultStage 30, ResultStage 34, ResultStage 32, ResultStage 36, ResultStage 28)
[2025-11-28T07:56:32.952+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:32.957+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:32.972+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 32.0 KiB, free 433.2 MiB)
[2025-11-28T07:56:32.973+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:32.993+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:32.997+0000] {subprocess.py:106} INFO - 25/11/28 07:56:32 INFO SparkContext: Created broadcast 62 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:33.008+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.30.0.7:45999 (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:33.032+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.30.0.7:43506
[2025-11-28T07:56:33.057+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:33.236+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 21) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:33.244+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 20) in 348 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:33.254+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: ResultStage 28 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 4.565 s
[2025-11-28T07:56:33.255+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:33.256+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-11-28T07:56:33.257+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
[2025-11-28T07:56:33.271+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Job 20 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 3.140745 s
[2025-11-28T07:56:33.374+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO CodeGenerator: Code generated in 155.618656 ms
[2025-11-28T07:56:33.438+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.30.0.7:45999 (size: 20.4 KiB, free: 434.2 MiB)
[2025-11-28T07:56:33.442+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO CodeGenerator: Code generated in 41.761131 ms
[2025-11-28T07:56:33.463+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:33.472+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Got job 25 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:33.478+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Final stage: ResultStage 38 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:33.490+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
[2025-11-28T07:56:33.493+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:33.497+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[87] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:33.499+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 43.3 KiB, free 433.1 MiB)
[2025-11-28T07:56:33.501+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.30.0.7:43506
[2025-11-28T07:56:33.518+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.1 MiB)
[2025-11-28T07:56:33.536+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 68d0d8c522fe:36705 (size: 19.3 KiB, free: 433.8 MiB)
[2025-11-28T07:56:33.551+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:33.561+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[87] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:33.574+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-11-28T07:56:33.579+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 270.0 B, free 433.1 MiB)
[2025-11-28T07:56:33.597+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 68d0d8c522fe:36705 (size: 270.0 B, free: 433.8 MiB)
[2025-11-28T07:56:33.614+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 68d0d8c522fe:36705 in memory (size: 18.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:33.625+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO SparkContext: Created broadcast 64 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:33.680+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.30.0.7:45999 in memory (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-28T07:56:33.702+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-11-28T07:56:33.741+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:33.744+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:33.747+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:33.748+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO SparkContext: Created broadcast 65 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:33.780+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 22) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:33.783+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 68d0d8c522fe:36705 in memory (size: 17.3 KiB, free: 433.9 MiB)
[2025-11-28T07:56:33.799+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 21) in 554 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:33.812+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-11-28T07:56:33.814+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: ResultStage 30 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 4.257 s
[2025-11-28T07:56:33.815+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:33.818+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-11-28T07:56:33.827+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO DAGScheduler: Job 21 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 2.857263 s
[2025-11-28T07:56:33.872+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.30.0.7:45999 in memory (size: 17.3 KiB, free: 434.2 MiB)
[2025-11-28T07:56:33.945+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.30.0.7:45999 (size: 19.0 KiB, free: 434.2 MiB)
[2025-11-28T07:56:33.955+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 433.2 MiB)
[2025-11-28T07:56:33.967+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 68d0d8c522fe:36705 (size: 15.6 KiB, free: 433.9 MiB)
[2025-11-28T07:56:33.970+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO SparkContext: Created broadcast 66 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:33.973+0000] {subprocess.py:106} INFO - 25/11/28 07:56:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.30.0.7:43506
[2025-11-28T07:56:34.060+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-11-28T07:56:34.125+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:34.128+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:34.145+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:34.146+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO SparkContext: Created broadcast 67 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:34.237+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 23) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:34.241+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 68d0d8c522fe:36705 in memory (size: 20.4 KiB, free: 433.9 MiB)
[2025-11-28T07:56:34.376+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 22) in 605 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:34.378+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-11-28T07:56:34.400+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.30.0.7:45999 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-11-28T07:56:34.419+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO DAGScheduler: ResultStage 32 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 4.293 s
[2025-11-28T07:56:34.427+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:34.435+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
[2025-11-28T07:56:34.436+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO DAGScheduler: Job 22 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 2.859838 s
[2025-11-28T07:56:34.449+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 358.0 B, free 433.2 MiB)
[2025-11-28T07:56:34.451+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 68d0d8c522fe:36705 (size: 358.0 B, free: 433.9 MiB)
[2025-11-28T07:56:34.453+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO SparkContext: Created broadcast 68 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:34.484+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.30.0.7:45999 (size: 18.7 KiB, free: 434.2 MiB)
[2025-11-28T07:56:34.519+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 32.0 KiB, free 433.2 MiB)
[2025-11-28T07:56:34.522+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.2 MiB)
[2025-11-28T07:56:34.526+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:34.559+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO SparkContext: Created broadcast 69 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:34.588+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.30.0.7:43506
[2025-11-28T07:56:34.825+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 24) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:34.826+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 23) in 601 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:34.828+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool
[2025-11-28T07:56:34.839+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO DAGScheduler: ResultStage 34 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 4.274 s
[2025-11-28T07:56:34.840+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:34.855+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
[2025-11-28T07:56:34.858+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO DAGScheduler: Job 23 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 2.857906 s
[2025-11-28T07:56:34.944+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 433.1 MiB)
[2025-11-28T07:56:34.959+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 68d0d8c522fe:36705 (size: 32.1 KiB, free: 433.8 MiB)
[2025-11-28T07:56:34.960+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO SparkContext: Created broadcast 70 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:34.973+0000] {subprocess.py:106} INFO - 25/11/28 07:56:34 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.30.0.7:45999 (size: 20.2 KiB, free: 434.2 MiB)
[2025-11-28T07:56:35.012+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.30.0.7:43506
[2025-11-28T07:56:35.017+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-11-28T07:56:35.025+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:35.031+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:35.034+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO SparkContext: Created broadcast 71 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:35.111+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 25) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:35.114+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 24) in 291 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:35.121+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-11-28T07:56:35.123+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: ResultStage 36 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 4.112 s
[2025-11-28T07:56:35.127+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:35.135+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-11-28T07:56:35.139+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Job 24 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 2.675797 s
[2025-11-28T07:56:35.147+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO CodeGenerator: Code generated in 17.620365 ms
[2025-11-28T07:56:35.153+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 1126.0 B, free 433.1 MiB)
[2025-11-28T07:56:35.162+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 68d0d8c522fe:36705 (size: 1126.0 B, free: 433.8 MiB)
[2025-11-28T07:56:35.167+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO SparkContext: Created broadcast 72 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:35.169+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.30.0.7:45999 (size: 19.3 KiB, free: 434.1 MiB)
[2025-11-28T07:56:35.188+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.30.0.7:43506
[2025-11-28T07:56:35.199+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:35.208+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:35.210+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:35.211+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO SparkContext: Created broadcast 73 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:35.289+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 25) in 180 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:35.291+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-11-28T07:56:35.293+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: ResultStage 38 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 1.818 s
[2025-11-28T07:56:35.294+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:35.295+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
[2025-11-28T07:56:35.297+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Job 25 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 1.836544 s
[2025-11-28T07:56:35.306+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 433.0 MiB)
[2025-11-28T07:56:35.309+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 68d0d8c522fe:36705 (size: 3.6 KiB, free: 433.7 MiB)
[2025-11-28T07:56:35.310+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO SparkContext: Created broadcast 74 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:35.338+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:35.376+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:35.383+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:35.385+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:35.387+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO SparkContext: Created broadcast 75 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:35.410+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 68d0d8c522fe:36705 in memory (size: 18.7 KiB, free: 433.8 MiB)
[2025-11-28T07:56:35.415+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.30.0.7:45999 in memory (size: 18.7 KiB, free: 434.2 MiB)
[2025-11-28T07:56:35.437+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 68d0d8c522fe:36705 in memory (size: 19.3 KiB, free: 433.8 MiB)
[2025-11-28T07:56:35.438+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.30.0.7:45999 in memory (size: 19.3 KiB, free: 434.2 MiB)
[2025-11-28T07:56:35.452+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 68d0d8c522fe:36705 in memory (size: 19.0 KiB, free: 433.8 MiB)
[2025-11-28T07:56:35.466+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.30.0.7:45999 in memory (size: 19.0 KiB, free: 434.2 MiB)
[2025-11-28T07:56:35.475+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:35.487+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 68d0d8c522fe:36705 in memory (size: 20.2 KiB, free: 433.9 MiB)
[2025-11-28T07:56:35.535+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.30.0.7:45999 in memory (size: 20.2 KiB, free: 434.2 MiB)
[2025-11-28T07:56:35.550+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:35.560+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.9 MiB)
[2025-11-28T07:56:35.612+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Started reading broadcast variable 64 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:35.641+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Reading broadcast variable 64 took 28 ms
[2025-11-28T07:56:35.671+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Started reading broadcast variable 66 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:35.673+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Reading broadcast variable 66 took 0 ms
[2025-11-28T07:56:35.683+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Started reading broadcast variable 68 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:35.686+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Reading broadcast variable 68 took 0 ms
[2025-11-28T07:56:35.693+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Started reading broadcast variable 70 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:35.695+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Reading broadcast variable 70 took 0 ms
[2025-11-28T07:56:35.707+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Started reading broadcast variable 72 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:35.710+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Reading broadcast variable 72 took 0 ms
[2025-11-28T07:56:35.721+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Started reading broadcast variable 74 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:35.723+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TorrentBroadcast: Reading broadcast variable 74 took 0 ms
[2025-11-28T07:56:35.834+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO CodeGenerator: Code generated in 69.376775 ms
[2025-11-28T07:56:35.902+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Registering RDD 92 (create at <unknown>:0) as input to shuffle 13
[2025-11-28T07:56:35.905+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Got map stage job 26 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:35.906+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (create at <unknown>:0)
[2025-11-28T07:56:35.907+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:35.908+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:35.908+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[92] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:35.930+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 132.9 KiB, free 433.3 MiB)
[2025-11-28T07:56:35.934+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 46.1 KiB, free 433.3 MiB)
[2025-11-28T07:56:35.936+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 68d0d8c522fe:36705 (size: 46.1 KiB, free: 433.9 MiB)
[2025-11-28T07:56:35.938+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:35.939+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[92] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:35.939+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-11-28T07:56:35.943+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 26) (172.30.0.7, executor 0, partition 0, ANY, 15035 bytes)
[2025-11-28T07:56:35.972+0000] {subprocess.py:106} INFO - 25/11/28 07:56:35 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.30.0.7:45999 (size: 46.1 KiB, free: 434.2 MiB)
[2025-11-28T07:56:36.156+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.30.0.7:45999 (size: 270.0 B, free: 434.2 MiB)
[2025-11-28T07:56:36.178+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.30.0.7:45999 (size: 15.6 KiB, free: 434.2 MiB)
[2025-11-28T07:56:36.221+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.30.0.7:45999 (size: 358.0 B, free: 434.2 MiB)
[2025-11-28T07:56:36.260+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.30.0.7:45999 (size: 32.1 KiB, free: 434.1 MiB)
[2025-11-28T07:56:36.289+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.30.0.7:45999 (size: 1126.0 B, free: 434.1 MiB)
[2025-11-28T07:56:36.322+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.30.0.7:45999 (size: 3.6 KiB, free: 434.1 MiB)
[2025-11-28T07:56:36.353+0000] {subprocess.py:106} INFO - 25/11/28 07:56:36 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.1 MiB)
[2025-11-28T07:56:37.507+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 26) in 1565 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:37.513+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-11-28T07:56:37.516+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: ShuffleMapStage 39 (create at <unknown>:0) finished in 1.603 s
[2025-11-28T07:56:37.520+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:37.527+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:37.533+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:37.534+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:37.535+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1311795, minimum partition size: 1048576
[2025-11-28T07:56:37.598+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO CodeGenerator: Code generated in 16.118302 ms
[2025-11-28T07:56:37.646+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Registering RDD 96 (create at <unknown>:0) as input to shuffle 14
[2025-11-28T07:56:37.647+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Got map stage job 27 (create at <unknown>:0) with 2 output partitions
[2025-11-28T07:56:37.648+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (create at <unknown>:0)
[2025-11-28T07:56:37.649+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
[2025-11-28T07:56:37.650+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:37.651+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[96] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:37.676+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 133.5 KiB, free 433.1 MiB)
[2025-11-28T07:56:37.679+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 45.4 KiB, free 433.1 MiB)
[2025-11-28T07:56:37.681+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 68d0d8c522fe:36705 (size: 45.4 KiB, free: 433.8 MiB)
[2025-11-28T07:56:37.683+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:37.684+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[96] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-28T07:56:37.685+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO TaskSchedulerImpl: Adding task set 41.0 with 2 tasks resource profile 0
[2025-11-28T07:56:37.686+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 27) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9320 bytes)
[2025-11-28T07:56:37.706+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.30.0.7:45999 (size: 45.4 KiB, free: 434.1 MiB)
[2025-11-28T07:56:37.728+0000] {subprocess.py:106} INFO - 25/11/28 07:56:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.30.0.7:43506
[2025-11-28T07:56:38.143+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 28) (172.30.0.7, executor 0, partition 1, NODE_LOCAL, 9320 bytes)
[2025-11-28T07:56:38.150+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 27) in 459 ms on 172.30.0.7 (executor 0) (1/2)
[2025-11-28T07:56:38.384+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 28) in 242 ms on 172.30.0.7 (executor 0) (2/2)
[2025-11-28T07:56:38.386+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-11-28T07:56:38.390+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: ShuffleMapStage 41 (create at <unknown>:0) finished in 0.727 s
[2025-11-28T07:56:38.391+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:38.395+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: running: Set()
[2025-11-28T07:56:38.401+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:38.402+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:38.404+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 402653184, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:38.487+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-11-28T07:56:38.494+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.0 MiB)
[2025-11-28T07:56:38.495+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 68d0d8c522fe:36705 (size: 29.6 KiB, free: 433.8 MiB)
[2025-11-28T07:56:38.498+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO SparkContext: Created broadcast 78 from broadcast at SparkWrite.java:193
[2025-11-28T07:56:38.499+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO AppendDataExec: Start processing data source write support: IcebergBatchWrite(table=gold.fact_job_posting, format=PARQUET). The input RDD has 1 partitions.
[2025-11-28T07:56:38.505+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO SparkContext: Starting job: create at <unknown>:0
[2025-11-28T07:56:38.510+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: Got job 28 (create at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:38.511+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: Final stage: ResultStage 44 (create at <unknown>:0)
[2025-11-28T07:56:38.512+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
[2025-11-28T07:56:38.513+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:38.514+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: Submitting ResultStage 44 (ShuffledRowRDD[97] at create at <unknown>:0), which has no missing parents
[2025-11-28T07:56:38.520+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 10.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:38.524+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 433.0 MiB)
[2025-11-28T07:56:38.527+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 68d0d8c522fe:36705 (size: 5.8 KiB, free: 433.8 MiB)
[2025-11-28T07:56:38.528+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:38.530+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (ShuffledRowRDD[97] at create at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:38.531+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-11-28T07:56:38.534+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 29) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:38.561+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.30.0.7:45999 (size: 5.8 KiB, free: 434.0 MiB)
[2025-11-28T07:56:38.565+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.30.0.7:43506
[2025-11-28T07:56:38.587+0000] {subprocess.py:106} INFO - 25/11/28 07:56:38 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.30.0.7:45999 (size: 29.6 KiB, free: 434.0 MiB)
[2025-11-28T07:56:54.717+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 29) in 16185 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:54.719+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-11-28T07:56:54.721+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO DAGScheduler: ResultStage 44 (create at <unknown>:0) finished in 16.204 s
[2025-11-28T07:56:54.722+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:54.722+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
[2025-11-28T07:56:54.723+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO DAGScheduler: Job 28 finished: create at <unknown>:0, took 16.214112 s
[2025-11-28T07:56:54.723+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.fact_job_posting, format=PARQUET) is committing.
[2025-11-28T07:56:54.724+0000] {subprocess.py:106} INFO - 25/11/28 07:56:54 INFO SparkWrite: Committing append with 67 new data files to table gold.fact_job_posting
[2025-11-28T07:56:55.338+0000] {subprocess.py:106} INFO - 25/11/28 07:56:55 INFO SnapshotProducer: Committed snapshot 5447257330616305729 (MergeAppend)
[2025-11-28T07:56:55.366+0000] {subprocess.py:106} INFO - 25/11/28 07:56:55 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=gold.fact_job_posting, snapshotId=5447257330616305729, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.641709101S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=67}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=67}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=18644}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=18644}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=745407}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=745407}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.3, app-id=app-20251128075537-0002, engine-name=spark, iceberg-version=Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}}
[2025-11-28T07:56:55.367+0000] {subprocess.py:106} INFO - 25/11/28 07:56:55 INFO SparkWrite: Committed in 642 ms
[2025-11-28T07:56:55.368+0000] {subprocess.py:106} INFO - 25/11/28 07:56:55 INFO AppendDataExec: Data source write support IcebergBatchWrite(table=gold.fact_job_posting, format=PARQUET) committed.
[2025-11-28T07:56:56.271+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO HiveTableOperations: Committed to table hive_catalog.gold.fact_job_posting with the new metadata location hdfs://dinhhoa-master:9000/user/ndh/warehouse/gold.db/fact_job_posting/metadata/00000-e4b2c622-28a9-4238-b954-d2eaf0c4e22a.metadata.json
[2025-11-28T07:56:56.275+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BaseMetastoreTableOperations: Successfully committed to table hive_catalog.gold.fact_job_posting in 904 ms
[2025-11-28T07:56:56.282+0000] {subprocess.py:106} INFO -  Gold layer successfully built!
[2025-11-28T07:56:56.491+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:56.492+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.496+0000] {subprocess.py:106} INFO - Pushed Filters: skills_required IS NOT NULL
[2025-11-28T07:56:56.498+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(skills_required#3),(size(skills_required#3, true) > 0)
[2025-11-28T07:56:56.500+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:56.501+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:56.502+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.503+0000] {subprocess.py:106} INFO - Pushed Filters: skills_required IS NOT NULL
[2025-11-28T07:56:56.504+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(skills_required#384),(size(skills_required#384, true) > 0)
[2025-11-28T07:56:56.505+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:56.505+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:56.506+0000] {subprocess.py:106} INFO - Pushing operators to hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.507+0000] {subprocess.py:106} INFO - Pushed Filters: location IS NOT NULL
[2025-11-28T07:56:56.508+0000] {subprocess.py:106} INFO - Post-Scan Filters: isnotnull(location#437)
[2025-11-28T07:56:56.509+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:56.510+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:56.510+0000] {subprocess.py:106} INFO - Output: location#2, skills_required#3, job_link#5
[2025-11-28T07:56:56.511+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:56.512+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:56.513+0000] {subprocess.py:106} INFO - Output: skills_required#384
[2025-11-28T07:56:56.514+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:56.514+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO V2ScanRelationPushDown:
[2025-11-28T07:56:56.515+0000] {subprocess.py:106} INFO - Output: location#437
[2025-11-28T07:56:56.516+0000] {subprocess.py:106} INFO - 
[2025-11-28T07:56:56.516+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter skills_required IS NOT NULL
[2025-11-28T07:56:56.518+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.557+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.559+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter skills_required IS NOT NULL
[2025-11-28T07:56:56.560+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.603+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.605+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SnapshotScan: Scanning table hive_catalog.silver.it_jobs_clean snapshot 1256011238719753081 created at 2025-11-28T07:55:18.235+00:00 with filter location IS NOT NULL
[2025-11-28T07:56:56.607+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BaseDistributedDataScan: Planning file tasks locally for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.645+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkPartitioningAwareScan: Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.silver.it_jobs_clean
[2025-11-28T07:56:56.671+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:56.675+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:56.676+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:56.678+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkContext: Created broadcast 80 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:56.694+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 32.0 KiB, free 432.9 MiB)
[2025-11-28T07:56:56.698+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 432.9 MiB)
[2025-11-28T07:56:56.700+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:56.702+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkContext: Created broadcast 81 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:56.716+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 32.0 KiB, free 432.9 MiB)
[2025-11-28T07:56:56.719+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 432.8 MiB)
[2025-11-28T07:56:56.720+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:56.722+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkContext: Created broadcast 82 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:56.739+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 32.0 KiB, free 432.8 MiB)
[2025-11-28T07:56:56.772+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 68d0d8c522fe:36705 in memory (size: 46.1 KiB, free: 433.7 MiB)
[2025-11-28T07:56:56.774+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 432.8 MiB)
[2025-11-28T07:56:56.775+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:56.779+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkContext: Created broadcast 83 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:56.781+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.30.0.7:45999 in memory (size: 46.1 KiB, free: 434.1 MiB)
[2025-11-28T07:56:56.791+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:56.792+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 68d0d8c522fe:36705 in memory (size: 45.4 KiB, free: 433.8 MiB)
[2025-11-28T07:56:56.793+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:56.795+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:56.797+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkContext: Created broadcast 84 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:56.799+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.30.0.7:45999 in memory (size: 45.4 KiB, free: 434.1 MiB)
[2025-11-28T07:56:56.807+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 68d0d8c522fe:36705 in memory (size: 29.6 KiB, free: 433.8 MiB)
[2025-11-28T07:56:56.814+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.30.0.7:45999 in memory (size: 29.6 KiB, free: 434.1 MiB)
[2025-11-28T07:56:56.825+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-11-28T07:56:56.827+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 68d0d8c522fe:36705 in memory (size: 5.8 KiB, free: 433.8 MiB)
[2025-11-28T07:56:56.828+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.1 MiB)
[2025-11-28T07:56:56.833+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.30.0.7:45999 in memory (size: 5.8 KiB, free: 434.1 MiB)
[2025-11-28T07:56:56.837+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:56.840+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO SparkContext: Created broadcast 85 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:56.849+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.8 MiB)
[2025-11-28T07:56:56.976+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO CodeGenerator: Code generated in 42.459151 ms
[2025-11-28T07:56:56.989+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO DAGScheduler: Registering RDD 101 (count at <unknown>:0) as input to shuffle 15
[2025-11-28T07:56:56.990+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO DAGScheduler: Got map stage job 29 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:56.992+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (count at <unknown>:0)
[2025-11-28T07:56:56.997+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:56.999+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:57.000+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[101] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:56:57.002+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 40.3 KiB, free 433.1 MiB)
[2025-11-28T07:56:57.006+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 433.1 MiB)
[2025-11-28T07:56:57.007+0000] {subprocess.py:106} INFO - 25/11/28 07:56:56 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 68d0d8c522fe:36705 (size: 17.6 KiB, free: 433.7 MiB)
[2025-11-28T07:56:57.008+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:57.009+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[101] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:57.011+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
[2025-11-28T07:56:57.012+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 30) (172.30.0.7, executor 0, partition 0, ANY, 14536 bytes)
[2025-11-28T07:56:57.034+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.30.0.7:45999 (size: 17.6 KiB, free: 434.1 MiB)
[2025-11-28T07:56:57.052+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO CodeGenerator: Code generated in 49.010414 ms
[2025-11-28T07:56:57.083+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Registering RDD 105 (count at <unknown>:0) as input to shuffle 16
[2025-11-28T07:56:57.091+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Got map stage job 30 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:57.096+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (count at <unknown>:0)
[2025-11-28T07:56:57.102+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:57.106+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:57.113+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[105] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:56:57.115+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 38.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:57.116+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 433.0 MiB)
[2025-11-28T07:56:57.117+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 68d0d8c522fe:36705 (size: 16.7 KiB, free: 433.7 MiB)
[2025-11-28T07:56:57.118+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:57.120+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[105] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:57.121+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-11-28T07:56:57.277+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.1 MiB)
[2025-11-28T07:56:57.757+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 31) (172.30.0.7, executor 0, partition 0, ANY, 14455 bytes)
[2025-11-28T07:56:57.762+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 30) in 748 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:57.765+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-11-28T07:56:57.780+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: ShuffleMapStage 45 (count at <unknown>:0) finished in 0.771 s
[2025-11-28T07:56:57.788+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:57.792+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: running: Set(ShuffleMapStage 46)
[2025-11-28T07:56:57.795+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:57.798+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:57.800+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:57.806+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 433.0 MiB)
[2025-11-28T07:56:57.808+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:57.810+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO SparkContext: Created broadcast 88 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:57.811+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.30.0.7:45999 (size: 16.7 KiB, free: 434.1 MiB)
[2025-11-28T07:56:57.843+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:57.949+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO CodeGenerator: Code generated in 58.716898 ms
[2025-11-28T07:56:57.963+0000] {subprocess.py:106} INFO - 25/11/28 07:56:57 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.1 MiB)
[2025-11-28T07:56:58.032+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:58.055+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Got job 31 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:58.063+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:58.067+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-11-28T07:56:58.076+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:58.077+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[108] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:58.082+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 45.9 KiB, free 432.9 MiB)
[2025-11-28T07:56:58.091+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 432.9 MiB)
[2025-11-28T07:56:58.098+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 68d0d8c522fe:36705 (size: 20.4 KiB, free: 433.7 MiB)
[2025-11-28T07:56:58.101+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:58.102+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[108] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:58.104+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-11-28T07:56:58.300+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 32) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:58.304+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 31) in 545 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:58.308+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-11-28T07:56:58.314+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: ShuffleMapStage 46 (count at <unknown>:0) finished in 1.211 s
[2025-11-28T07:56:58.318+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:56:58.328+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: running: Set(ResultStage 48)
[2025-11-28T07:56:58.330+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:56:58.332+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: failed: Set()
[2025-11-28T07:56:58.342+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.30.0.7:45999 (size: 20.4 KiB, free: 434.0 MiB)
[2025-11-28T07:56:58.345+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 32.0 KiB, free 432.9 MiB)
[2025-11-28T07:56:58.348+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 432.8 MiB)
[2025-11-28T07:56:58.359+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:58.363+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 90 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:58.364+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.30.0.7:43506
[2025-11-28T07:56:58.393+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:56:58.475+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 32) in 183 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:58.478+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-11-28T07:56:58.480+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 0.399 s
[2025-11-28T07:56:58.481+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:58.490+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-11-28T07:56:58.499+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Job 31 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 0.442879 s
[2025-11-28T07:56:58.503+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 432.8 MiB)
[2025-11-28T07:56:58.505+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 68d0d8c522fe:36705 (size: 15.6 KiB, free: 433.6 MiB)
[2025-11-28T07:56:58.514+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 91 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:58.523+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO CodeGenerator: Code generated in 73.534044 ms
[2025-11-28T07:56:58.558+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 32.0 KiB, free 432.8 MiB)
[2025-11-28T07:56:58.581+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 432.8 MiB)
[2025-11-28T07:56:58.584+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.6 MiB)
[2025-11-28T07:56:58.589+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:58.591+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:58.594+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Final stage: ResultStage 50 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
[2025-11-28T07:56:58.596+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
[2025-11-28T07:56:58.597+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 92 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:58.598+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:58.601+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[111] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
[2025-11-28T07:56:58.609+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 42.6 KiB, free 432.7 MiB)
[2025-11-28T07:56:58.682+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 432.7 MiB)
[2025-11-28T07:56:58.686+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 68d0d8c522fe:36705 (size: 19.0 KiB, free: 433.6 MiB)
[2025-11-28T07:56:58.689+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:58.691+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[111] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:58.694+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
[2025-11-28T07:56:58.699+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.6 MiB)
[2025-11-28T07:56:58.715+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 33) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:56:58.724+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 68d0d8c522fe:36705 in memory (size: 16.7 KiB, free: 433.6 MiB)
[2025-11-28T07:56:58.729+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.30.0.7:45999 in memory (size: 16.7 KiB, free: 434.0 MiB)
[2025-11-28T07:56:58.751+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 68d0d8c522fe:36705 in memory (size: 20.4 KiB, free: 433.7 MiB)
[2025-11-28T07:56:58.773+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.30.0.7:45999 in memory (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-28T07:56:58.776+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.30.0.7:45999 (size: 19.0 KiB, free: 434.0 MiB)
[2025-11-28T07:56:58.788+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 68d0d8c522fe:36705 in memory (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:58.869+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.30.0.7:43506
[2025-11-28T07:56:58.871+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 68d0d8c522fe:36705 in memory (size: 17.6 KiB, free: 433.7 MiB)
[2025-11-28T07:56:58.886+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.30.0.7:45999 in memory (size: 17.6 KiB, free: 434.1 MiB)
[2025-11-28T07:56:58.941+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 33) in 253 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:56:58.942+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool
[2025-11-28T07:56:58.945+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: ResultStage 50 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 0.337 s
[2025-11-28T07:56:58.946+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:56:58.947+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
[2025-11-28T07:56:58.948+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 0.361214 s
[2025-11-28T07:56:58.953+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 358.0 B, free 433.0 MiB)
[2025-11-28T07:56:58.955+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 68d0d8c522fe:36705 (size: 358.0 B, free: 433.7 MiB)
[2025-11-28T07:56:58.957+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 94 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
[2025-11-28T07:56:58.965+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-11-28T07:56:58.967+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 432.9 MiB)
[2025-11-28T07:56:58.968+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 68d0d8c522fe:36705 (size: 29.9 KiB, free: 433.7 MiB)
[2025-11-28T07:56:58.969+0000] {subprocess.py:106} INFO - 25/11/28 07:56:58 INFO SparkContext: Created broadcast 95 from broadcast at SparkBatch.java:79
[2025-11-28T07:56:59.055+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO TorrentBroadcast: Started reading broadcast variable 91 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-28T07:56:59.059+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO TorrentBroadcast: Reading broadcast variable 91 took 0 ms
[2025-11-28T07:56:59.177+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO CodeGenerator: Code generated in 105.758839 ms
[2025-11-28T07:56:59.198+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Registering RDD 115 (count at <unknown>:0) as input to shuffle 17
[2025-11-28T07:56:59.201+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Got map stage job 33 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:56:59.203+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Final stage: ShuffleMapStage 51 (count at <unknown>:0)
[2025-11-28T07:56:59.205+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Parents of final stage: List()
[2025-11-28T07:56:59.207+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:56:59.209+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[115] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:56:59.212+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 73.0 KiB, free 432.9 MiB)
[2025-11-28T07:56:59.217+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 432.8 MiB)
[2025-11-28T07:56:59.220+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 68d0d8c522fe:36705 (size: 29.0 KiB, free: 433.6 MiB)
[2025-11-28T07:56:59.222+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:56:59.227+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[115] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:56:59.229+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-11-28T07:56:59.232+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 34) (172.30.0.7, executor 0, partition 0, ANY, 14656 bytes)
[2025-11-28T07:56:59.272+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.30.0.7:45999 (size: 29.0 KiB, free: 434.0 MiB)
[2025-11-28T07:56:59.393+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.30.0.7:45999 (size: 15.6 KiB, free: 434.0 MiB)
[2025-11-28T07:56:59.426+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.30.0.7:45999 (size: 358.0 B, free: 434.0 MiB)
[2025-11-28T07:56:59.537+0000] {subprocess.py:106} INFO - 25/11/28 07:56:59 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.30.0.7:45999 (size: 29.9 KiB, free: 434.0 MiB)
[2025-11-28T07:57:00.131+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 34) in 907 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:57:00.133+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-11-28T07:57:00.134+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: ShuffleMapStage 51 (count at <unknown>:0) finished in 0.935 s
[2025-11-28T07:57:00.135+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:57:00.136+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: running: Set()
[2025-11-28T07:57:00.136+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:57:00.137+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: failed: Set()
[2025-11-28T07:57:00.140+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-28T07:57:00.189+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO CodeGenerator: Code generated in 25.572982 ms
[2025-11-28T07:57:00.215+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Registering RDD 118 (count at <unknown>:0) as input to shuffle 18
[2025-11-28T07:57:00.216+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Got map stage job 34 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:57:00.218+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (count at <unknown>:0)
[2025-11-28T07:57:00.218+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-11-28T07:57:00.219+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:57:00.220+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[118] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:57:00.225+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 74.3 KiB, free 432.8 MiB)
[2025-11-28T07:57:00.228+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 432.7 MiB)
[2025-11-28T07:57:00.229+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 68d0d8c522fe:36705 (size: 29.6 KiB, free: 433.6 MiB)
[2025-11-28T07:57:00.230+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:57:00.232+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[118] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:57:00.233+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-11-28T07:57:00.234+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 35) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9320 bytes)
[2025-11-28T07:57:00.252+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.30.0.7:45999 (size: 29.6 KiB, free: 434.0 MiB)
[2025-11-28T07:57:00.288+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.30.0.7:43506
[2025-11-28T07:57:00.368+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 35) in 134 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:57:00.370+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-11-28T07:57:00.371+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: ShuffleMapStage 53 (count at <unknown>:0) finished in 0.148 s
[2025-11-28T07:57:00.372+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: looking for newly runnable stages
[2025-11-28T07:57:00.373+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: running: Set()
[2025-11-28T07:57:00.373+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: waiting: Set()
[2025-11-28T07:57:00.374+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: failed: Set()
[2025-11-28T07:57:00.400+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO CodeGenerator: Code generated in 11.824275 ms
[2025-11-28T07:57:00.416+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO SparkContext: Starting job: count at <unknown>:0
[2025-11-28T07:57:00.419+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Got job 35 (count at <unknown>:0) with 1 output partitions
[2025-11-28T07:57:00.420+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Final stage: ResultStage 56 (count at <unknown>:0)
[2025-11-28T07:57:00.421+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
[2025-11-28T07:57:00.423+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Missing parents: List()
[2025-11-28T07:57:00.425+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[121] at count at <unknown>:0), which has no missing parents
[2025-11-28T07:57:00.431+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 12.5 KiB, free 432.7 MiB)
[2025-11-28T07:57:00.432+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 432.7 MiB)
[2025-11-28T07:57:00.433+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 68d0d8c522fe:36705 (size: 5.9 KiB, free: 433.6 MiB)
[2025-11-28T07:57:00.434+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585
[2025-11-28T07:57:00.436+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[121] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-28T07:57:00.437+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
[2025-11-28T07:57:00.438+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 36) (172.30.0.7, executor 0, partition 0, NODE_LOCAL, 9331 bytes)
[2025-11-28T07:57:00.461+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.30.0.7:45999 (size: 5.9 KiB, free: 434.0 MiB)
[2025-11-28T07:57:00.469+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.30.0.7:43506
[2025-11-28T07:57:00.496+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 36) in 60 ms on 172.30.0.7 (executor 0) (1/1)
[2025-11-28T07:57:00.497+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool
[2025-11-28T07:57:00.499+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: ResultStage 56 (count at <unknown>:0) finished in 0.075 s
[2025-11-28T07:57:00.500+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-28T07:57:00.502+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
[2025-11-28T07:57:00.506+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO DAGScheduler: Job 35 finished: count at <unknown>:0, took 0.081711 s
[2025-11-28T07:57:00.507+0000] {subprocess.py:106} INFO -  Fact record count: 18644
[2025-11-28T07:57:00.509+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-11-28T07:57:00.547+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO SparkUI: Stopped Spark web UI at http://68d0d8c522fe:4040
[2025-11-28T07:57:00.574+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-11-28T07:57:00.576+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[2025-11-28T07:57:00.623+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-11-28T07:57:00.682+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO MemoryStore: MemoryStore cleared
[2025-11-28T07:57:00.690+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO BlockManager: BlockManager stopped
[2025-11-28T07:57:00.715+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-11-28T07:57:00.728+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-11-28T07:57:00.778+0000] {subprocess.py:106} INFO - 25/11/28 07:57:00 INFO SparkContext: Successfully stopped SparkContext
[2025-11-28T07:57:01.160+0000] {subprocess.py:106} INFO - 25/11/28 07:57:01 INFO ShutdownHookManager: Shutdown hook called
[2025-11-28T07:57:01.161+0000] {subprocess.py:106} INFO - 25/11/28 07:57:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-e44a46b6-b648-44ff-bc83-4d7ea65434cc
[2025-11-28T07:57:01.167+0000] {subprocess.py:106} INFO - 25/11/28 07:57:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-060cdf51-1639-4b08-8931-96b268862d00
[2025-11-28T07:57:01.174+0000] {subprocess.py:106} INFO - 25/11/28 07:57:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-e44a46b6-b648-44ff-bc83-4d7ea65434cc/pyspark-d1ec5509-2740-4429-9c8e-7b9c18d92ba9
[2025-11-28T07:57:01.342+0000] {subprocess.py:110} INFO - Command exited with return code 0
[2025-11-28T07:57:01.471+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-11-28T07:57:01.472+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=crawl_etl_itjob, task_id=build_gold, run_id=scheduled__2025-11-27T02:00:00+00:00, execution_date=20251127T020000, start_date=20251128T075527, end_date=20251128T075701
[2025-11-28T07:57:01.605+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-28T07:57:01.660+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-28T07:57:01.663+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
