[2025-11-20T10:08:18.777+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:08:18.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:08:18.779+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:08:18.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:08:18.797+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:08:18.836+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:08:18.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:08:18.869+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:08:18.869+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:08:18.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.120 seconds
[2025-11-20T10:08:48.936+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:08:48.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:08:48.938+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:08:48.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:08:48.955+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:08:48.989+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:08:48.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:08:49.020+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:08:49.020+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:08:49.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:09:19.277+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:09:19.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:09:19.279+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:09:19.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:09:19.304+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:09:19.350+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:09:19.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:09:19.390+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:09:19.390+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:09:19.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.162 seconds
[2025-11-20T10:09:49.902+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:09:49.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:09:49.905+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:09:49.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:09:49.926+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:09:49.971+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:09:49.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:09:50.005+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:09:50.005+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:09:50.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.136 seconds
[2025-11-20T10:10:22.554+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:10:22.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:10:22.556+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:10:22.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:10:22.575+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:10:22.628+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:10:22.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:10:22.685+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:10:22.685+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:10:22.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.192 seconds
[2025-11-20T10:10:54.890+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:10:54.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:10:54.893+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:10:54.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:10:54.925+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:10:54.981+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:10:54.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:10:55.061+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:10:55.060+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:10:55.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.254 seconds
[2025-11-20T10:11:27.319+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:11:27.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:11:27.322+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:11:27.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:11:27.341+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:11:27.378+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:11:27.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:11:27.410+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:11:27.410+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:11:27.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.132 seconds
[2025-11-20T10:12:00.922+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:12:00.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:12:00.924+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:12:00.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:12:00.945+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:12:00.978+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:12:00.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:12:01.004+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:12:01.004+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:12:01.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.108 seconds
[2025-11-20T10:12:33.102+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:12:33.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:12:33.105+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:12:33.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:12:33.124+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:12:33.171+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:12:33.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:12:33.209+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:12:33.209+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:12:33.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.140 seconds
[2025-11-20T10:13:05.400+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:13:05.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:13:05.402+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:13:05.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:13:05.422+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:13:05.459+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:13:05.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:13:05.489+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:13:05.489+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:13:05.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.126 seconds
[2025-11-20T10:13:38.889+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:13:38.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:13:38.892+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:13:38.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:13:38.913+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:13:38.952+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:13:38.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:13:38.987+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:13:38.987+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:13:39.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.127 seconds
[2025-11-20T10:14:11.153+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:14:11.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:14:11.154+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:14:11.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:14:11.173+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:14:11.207+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:14:11.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:14:11.234+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:14:11.234+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:14:11.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T10:14:44.504+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:14:44.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:14:44.506+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:14:44.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:14:44.531+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:14:44.581+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:14:44.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:14:44.633+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:14:44.633+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:14:44.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.183 seconds
[2025-11-20T10:15:17.076+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:15:17.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:15:17.078+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:15:17.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:15:17.097+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:15:17.132+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:15:17.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:15:17.167+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:15:17.166+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:15:17.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.118 seconds
[2025-11-20T10:15:49.219+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:15:49.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:15:49.221+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:15:49.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:15:49.240+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:15:49.277+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:15:49.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:15:49.308+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:15:49.308+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:15:49.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.126 seconds
[2025-11-20T10:16:22.717+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:16:22.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:16:22.719+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:16:22.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:16:22.739+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:16:22.784+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:16:22.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:16:22.816+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:16:22.816+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:16:22.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-20T10:16:55.486+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:16:55.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:16:55.491+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:16:55.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:16:55.523+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:16:55.590+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:16:55.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:16:55.638+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:16:55.638+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:16:55.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.205 seconds
[2025-11-20T10:17:27.749+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:17:27.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:17:27.751+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:17:27.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:17:27.774+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:17:27.822+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:17:27.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:17:27.860+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:17:27.860+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:17:27.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.141 seconds
[2025-11-20T10:18:01.134+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:18:01.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:18:01.137+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:18:01.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:18:01.168+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:18:01.220+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:18:01.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:18:01.275+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:18:01.274+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:18:01.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.190 seconds
[2025-11-20T10:18:33.546+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:18:33.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:18:33.548+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:18:33.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:18:33.570+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:18:33.617+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:18:33.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:18:33.660+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:18:33.660+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:18:33.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.158 seconds
[2025-11-20T10:19:06.328+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:19:06.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:19:06.331+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:19:06.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:19:06.380+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:19:06.443+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:19:06.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:19:06.500+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:19:06.500+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:19:06.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.227 seconds
[2025-11-20T10:19:39.134+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:19:39.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:19:39.136+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:19:39.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:19:39.161+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:19:39.207+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:19:39.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:19:39.244+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:19:39.244+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:19:39.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.153 seconds
[2025-11-20T10:20:15.143+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:20:15.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:20:15.154+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:20:15.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:20:15.225+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:20:15.438+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:20:15.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:20:15.576+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:20:15.575+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:20:15.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.546 seconds
[2025-11-20T10:20:46.000+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:20:46.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:20:46.002+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:20:46.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:20:46.023+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:20:46.065+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:20:46.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:20:46.098+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:20:46.097+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:20:46.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.148 seconds
[2025-11-20T10:21:17.636+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:21:17.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:21:17.638+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:21:17.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:21:17.662+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:21:17.715+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:21:17.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:21:17.754+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:21:17.754+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:21:17.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.162 seconds
[2025-11-20T10:21:50.132+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:21:50.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:21:50.138+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:21:50.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:21:50.213+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:21:50.312+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:21:50.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:21:50.371+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:21:50.371+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:21:50.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.289 seconds
[2025-11-20T10:22:22.831+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:22:22.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:22:22.838+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:22:22.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:22:22.891+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:22:22.984+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:22:22.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:22:23.036+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:22:23.036+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:22:23.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.263 seconds
[2025-11-20T10:22:56.421+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:22:56.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:22:56.425+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:22:56.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:22:56.463+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:22:56.532+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:22:56.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:22:56.588+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:22:56.587+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:22:56.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.237 seconds
[2025-11-20T10:23:28.905+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:23:28.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:23:28.914+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:23:28.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:23:28.949+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:23:29.039+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:23:29.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:23:29.110+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:23:29.109+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:23:29.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.302 seconds
[2025-11-20T10:24:00.595+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:24:00.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:24:00.598+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:24:00.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:24:00.618+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:24:00.658+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:24:00.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:24:00.693+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:24:00.693+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:24:00.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.132 seconds
[2025-11-20T10:24:33.918+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:24:33.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:24:33.921+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:24:33.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:24:33.950+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:24:34.005+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:24:34.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:24:34.047+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:24:34.047+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:24:34.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.166 seconds
[2025-11-20T10:25:06.362+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:25:06.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:25:06.364+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:25:06.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:25:06.388+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:25:06.440+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:25:06.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:25:06.481+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:25:06.481+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:25:06.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.165 seconds
[2025-11-20T10:25:39.590+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:25:39.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:25:39.593+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:25:39.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:25:39.619+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:25:39.680+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:25:39.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:25:39.733+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:25:39.733+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:25:39.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.203 seconds
[2025-11-20T10:26:11.334+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:26:11.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:26:11.337+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:26:11.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:26:11.372+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:26:11.443+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:26:11.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:26:11.498+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:26:11.498+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:26:11.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.225 seconds
[2025-11-20T10:26:45.205+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:26:45.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:26:45.208+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:26:45.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:26:45.243+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:26:45.300+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:26:45.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:26:45.359+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:26:45.359+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:26:45.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.202 seconds
[2025-11-20T10:27:17.543+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:27:17.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:27:17.545+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:27:17.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:27:17.565+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:27:17.601+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:27:17.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:27:17.631+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:27:17.631+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:27:17.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.119 seconds
[2025-11-20T10:27:49.933+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:27:49.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:27:49.935+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:27:49.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:27:49.962+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:27:50.017+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:27:50.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:27:50.058+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:27:50.058+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:27:50.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.176 seconds
[2025-11-20T10:28:22.363+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:28:22.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:28:22.365+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:28:22.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:28:22.389+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:28:22.439+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:28:22.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:28:22.481+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:28:22.481+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:28:22.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.186 seconds
[2025-11-20T10:28:55.779+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:28:55.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:28:55.783+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:28:55.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:28:55.808+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:28:55.857+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:28:55.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:28:55.895+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:28:55.894+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:28:55.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.158 seconds
[2025-11-20T10:29:28.212+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:29:28.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:29:28.214+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:29:28.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:29:28.230+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:29:28.262+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:29:28.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:29:28.290+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:29:28.290+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:29:28.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.104 seconds
[2025-11-20T10:30:00.440+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:30:00.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:30:00.442+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:30:00.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:30:00.463+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:30:00.503+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:30:00.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:30:00.534+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:30:00.534+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:30:00.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.134 seconds
[2025-11-20T10:30:33.772+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:30:33.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:30:33.774+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:30:33.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:30:33.793+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:30:33.840+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:30:33.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:30:33.876+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:30:33.876+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:30:33.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.135 seconds
[2025-11-20T10:31:06.401+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:31:06.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:31:06.403+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:31:06.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:31:06.424+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:31:06.467+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:31:06.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:31:06.498+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:31:06.498+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:31:06.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.129 seconds
[2025-11-20T10:31:38.579+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:31:38.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:31:38.581+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:31:38.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:31:38.603+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:31:38.643+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:31:38.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:31:38.681+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:31:38.681+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:31:38.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.143 seconds
[2025-11-20T10:32:11.978+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:32:11.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:32:11.981+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:32:11.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:32:12.014+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:32:12.078+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:32:12.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:32:12.111+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:32:12.111+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:32:12.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.169 seconds
[2025-11-20T10:32:44.499+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:32:44.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:32:44.504+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:32:44.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:32:44.535+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:32:44.594+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:32:44.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:32:44.656+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:32:44.656+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:32:44.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.217 seconds
[2025-11-20T10:33:17.198+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:33:17.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:33:17.200+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:33:17.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:33:17.222+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:33:17.264+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:33:17.264+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:33:17.298+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:33:17.298+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:33:17.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.135 seconds
[2025-11-20T10:33:50.989+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:33:50.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:33:50.991+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:33:50.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:33:51.010+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:33:51.048+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:33:51.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:33:51.078+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:33:51.077+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:33:51.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.126 seconds
[2025-11-20T10:34:24.025+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:34:24.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:34:24.028+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:34:24.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:34:24.058+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:34:24.124+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:34:24.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:34:24.174+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:34:24.174+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:34:24.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.198 seconds
[2025-11-20T10:34:57.079+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:34:57.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:34:57.082+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:34:57.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:34:57.106+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:34:57.160+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:34:57.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:34:57.197+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:34:57.197+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:34:57.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.158 seconds
[2025-11-20T10:35:30.989+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:35:30.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:35:30.991+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:35:30.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:35:31.012+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:35:31.050+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:35:31.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:35:31.085+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:35:31.085+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:35:31.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.132 seconds
[2025-11-20T10:36:03.946+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:36:03.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:36:03.948+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:36:03.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:36:03.971+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:36:04.014+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:36:04.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:36:04.046+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:36:04.045+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:36:04.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.137 seconds
[2025-11-20T10:36:37.087+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:36:37.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:36:37.091+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:36:37.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:36:37.131+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:36:37.195+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:36:37.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:36:37.243+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:36:37.243+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:36:37.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.221 seconds
[2025-11-20T10:37:11.821+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:37:11.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:37:11.825+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:37:11.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:37:11.890+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:37:12.069+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:37:12.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:37:12.153+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:37:12.152+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:37:12.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.386 seconds
[2025-11-20T10:37:44.413+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:37:44.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:37:44.418+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:37:44.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:37:44.473+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:37:44.545+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:37:44.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:37:44.653+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:37:44.653+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:37:44.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.319 seconds
[2025-11-20T10:38:18.728+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:38:18.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:38:18.732+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:38:18.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:38:18.764+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:38:18.830+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:38:18.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:38:18.882+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:38:18.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:38:18.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.209 seconds
[2025-11-20T10:38:51.257+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:38:51.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:38:51.260+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:38:51.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:38:51.296+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:38:51.365+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:38:51.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:38:51.416+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:38:51.416+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:38:51.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.218 seconds
[2025-11-20T10:39:25.540+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:39:25.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:39:25.553+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:39:25.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:39:25.631+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:39:25.789+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:39:25.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:39:25.910+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:39:25.910+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:39:26.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.482 seconds
[2025-11-20T10:39:57.362+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:39:57.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:39:57.364+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:39:57.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:39:57.385+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:39:57.432+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:39:57.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:39:57.477+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:39:57.477+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:39:57.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.163 seconds
[2025-11-20T10:40:30.324+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:40:30.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:40:30.326+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:40:30.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:40:30.348+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:40:30.389+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:40:30.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:40:30.420+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:40:30.419+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:40:30.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.132 seconds
[2025-11-20T10:41:04.222+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:41:04.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:41:04.224+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:41:04.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:41:04.245+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:41:04.286+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:41:04.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:41:04.317+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:41:04.317+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:41:04.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-20T10:41:37.144+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:41:37.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:41:37.145+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:41:37.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:41:37.165+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:41:37.205+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:41:37.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:41:37.235+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:41:37.235+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:41:37.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.126 seconds
[2025-11-20T10:42:11.026+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:42:11.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:42:11.029+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:42:11.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:42:11.048+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:42:11.092+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:42:11.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:42:11.130+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:42:11.130+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:42:11.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.138 seconds
[2025-11-20T10:42:43.988+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:42:43.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:42:43.992+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:42:43.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:42:44.025+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:42:44.076+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:42:44.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:42:44.114+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:42:44.113+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:42:44.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.175 seconds
[2025-11-20T10:43:17.903+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:43:17.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:43:17.904+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:43:17.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:43:17.921+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:43:17.956+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:43:17.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:43:17.984+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:43:17.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:43:18.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.114 seconds
[2025-11-20T10:43:50.809+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:43:50.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:43:50.811+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:43:50.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:43:50.825+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:43:50.855+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:43:50.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:43:50.879+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:43:50.879+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:43:50.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.099 seconds
[2025-11-20T10:44:23.824+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:44:23.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:44:23.827+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:44:23.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:44:23.850+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:44:23.896+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:44:23.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:44:23.944+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:44:23.944+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:44:23.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.175 seconds
[2025-11-20T10:44:57.898+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:44:57.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:44:57.900+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:44:57.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:44:57.914+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:44:57.947+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:44:57.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:44:57.972+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:44:57.972+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:44:57.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.096 seconds
[2025-11-20T10:45:30.611+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:45:30.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:45:30.613+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:45:30.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:45:30.630+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:45:30.663+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:45:30.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:45:30.689+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:45:30.689+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:45:30.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:46:04.455+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:46:04.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:46:04.457+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:46:04.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:46:04.475+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:46:04.508+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:46:04.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:46:04.534+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:46:04.534+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:46:04.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.119 seconds
[2025-11-20T10:46:37.273+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:46:37.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:46:37.276+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:46:37.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:46:37.295+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:46:37.332+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:46:37.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:46:37.367+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:46:37.367+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:46:37.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.121 seconds
[2025-11-20T10:47:11.102+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:47:11.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:47:11.104+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:47:11.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:47:11.123+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:47:11.155+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:47:11.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:47:11.184+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:47:11.183+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:47:11.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.110 seconds
[2025-11-20T10:47:43.949+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:47:43.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:47:43.951+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:47:43.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:47:43.969+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:47:44.004+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:47:44.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:47:44.030+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:47:44.030+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:47:44.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.108 seconds
[2025-11-20T10:48:17.918+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:48:17.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:48:17.920+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:48:17.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:48:17.935+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:48:17.966+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:48:17.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:48:17.989+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:48:17.989+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:48:18.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.093 seconds
[2025-11-20T10:48:50.624+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:48:50.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:48:50.626+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:48:50.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:48:50.642+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:48:50.677+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:48:50.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:48:50.703+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:48:50.702+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:48:50.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.110 seconds
[2025-11-20T10:49:24.560+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:49:24.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:49:24.562+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:49:24.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:49:24.581+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:49:24.617+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:49:24.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:49:24.645+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:49:24.645+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:49:24.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.121 seconds
[2025-11-20T10:49:57.377+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:49:57.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:49:57.379+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:49:57.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:49:57.396+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:49:57.431+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:49:57.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:49:57.458+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:49:57.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:49:57.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:50:31.210+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:50:31.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:50:31.212+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:50:31.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:50:31.230+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:50:31.263+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:50:31.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:50:31.291+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:50:31.290+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:50:31.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:51:04.049+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:51:04.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:51:04.051+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:51:04.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:51:04.067+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:51:04.100+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:51:04.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:51:04.127+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:51:04.127+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:51:04.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.113 seconds
[2025-11-20T10:51:37.882+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:51:37.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:51:37.884+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:51:37.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:51:37.902+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:51:37.935+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:51:37.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:51:37.960+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:51:37.960+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:51:37.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:52:10.711+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:52:10.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:52:10.713+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:52:10.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:52:10.731+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:52:10.762+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:52:10.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:52:10.788+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:52:10.787+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:52:10.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.104 seconds
[2025-11-20T10:52:44.608+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:52:44.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:52:44.611+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:52:44.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:52:44.628+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:52:44.663+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:52:44.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:52:44.693+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:52:44.692+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:52:44.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T10:53:17.433+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:53:17.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:53:17.435+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:53:17.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:53:17.452+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:53:17.485+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:53:17.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:53:17.509+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:53:17.509+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:53:17.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.110 seconds
[2025-11-20T10:53:51.238+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:53:51.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:53:51.240+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:53:51.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:53:51.258+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:53:51.290+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:53:51.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:53:51.319+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:53:51.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:53:51.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.112 seconds
[2025-11-20T10:54:24.136+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:54:24.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:54:24.138+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:54:24.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:54:24.155+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:54:24.189+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:54:24.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:54:24.214+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:54:24.214+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:54:24.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.107 seconds
[2025-11-20T10:54:57.970+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:54:57.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:54:57.972+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:54:57.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:54:57.988+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:54:58.024+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:54:58.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:54:58.053+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:54:58.053+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:54:58.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:55:30.793+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:55:30.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:55:30.795+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:55:30.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:55:30.810+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:55:30.840+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:55:30.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:55:30.866+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:55:30.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:55:30.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.107 seconds
[2025-11-20T10:56:04.686+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:56:04.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:56:04.688+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:56:04.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:56:04.706+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:56:04.741+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:56:04.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:56:04.769+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:56:04.769+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:56:04.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.113 seconds
[2025-11-20T10:56:37.545+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:56:37.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:56:37.547+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:56:37.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:56:37.564+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:56:37.597+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:56:37.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:56:37.626+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:56:37.625+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:56:37.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.116 seconds
[2025-11-20T10:57:10.372+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:57:10.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:57:10.375+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:57:10.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:57:10.392+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:57:10.425+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:57:10.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:57:10.452+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:57:10.452+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:57:10.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:57:44.254+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:57:44.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:57:44.255+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:57:44.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:57:44.274+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:57:44.307+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:57:44.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:57:44.332+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:57:44.332+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:57:44.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.108 seconds
[2025-11-20T10:58:17.110+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:58:17.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:58:17.112+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:58:17.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:58:17.140+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:58:17.186+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:58:17.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:58:17.216+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:58:17.216+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:58:17.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.143 seconds
[2025-11-20T10:58:50.967+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:58:50.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:58:50.969+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:58:50.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:58:50.986+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:58:51.020+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:58:51.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:58:51.046+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:58:51.045+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:58:51.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.113 seconds
[2025-11-20T10:59:23.810+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:59:23.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:59:23.812+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:59:23.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:59:23.828+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:59:23.859+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:59:23.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:59:23.889+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:59:23.889+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:59:23.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T10:59:57.641+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:59:57.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T10:59:57.643+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:59:57.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:59:57.660+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T10:59:57.692+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:59:57.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T10:59:57.716+0000] {logging_mixin.py:190} INFO - [2025-11-20T10:59:57.716+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T10:59:57.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.107 seconds
[2025-11-20T11:00:30.446+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:00:30.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:00:30.448+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:00:30.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:00:30.465+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:00:30.498+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:00:30.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:00:30.523+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:00:30.522+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:00:30.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.112 seconds
[2025-11-20T11:01:04.378+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:01:04.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:01:04.380+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:01:04.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:01:04.398+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:01:04.431+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:01:04.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:01:04.460+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:01:04.460+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:01:04.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.116 seconds
[2025-11-20T11:01:37.234+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:01:37.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:01:37.236+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:01:37.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:01:37.256+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:01:37.294+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:01:37.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:01:37.339+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:01:37.339+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:01:37.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.141 seconds
[2025-11-20T11:02:11.088+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:02:11.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:02:11.090+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:02:11.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:02:11.106+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:02:11.139+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:02:11.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:02:11.165+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:02:11.165+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:02:11.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.109 seconds
[2025-11-20T11:02:43.922+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:02:43.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:02:43.924+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:02:43.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:02:43.939+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:02:43.970+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:02:43.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:02:43.996+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:02:43.996+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:02:44.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.104 seconds
[2025-11-20T11:03:17.768+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:03:17.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:03:17.769+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:03:17.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:03:17.787+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:03:17.824+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:03:17.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:03:17.855+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:03:17.855+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:03:17.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T11:03:50.577+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:03:50.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:03:50.580+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:03:50.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:03:50.597+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:03:50.630+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:03:50.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:03:50.658+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:03:50.658+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:03:50.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T11:04:24.512+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:04:24.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:04:24.514+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:04:24.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:04:24.532+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:04:24.569+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:04:24.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:04:24.595+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:04:24.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:04:24.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.117 seconds
[2025-11-20T11:04:57.376+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:04:57.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:04:57.379+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:04:57.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:04:57.398+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:04:57.436+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:04:57.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:04:57.473+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:04:57.472+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:04:57.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.139 seconds
[2025-11-20T11:05:31.252+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:05:31.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:05:31.254+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:05:31.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:05:31.273+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:05:31.306+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:05:31.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:05:31.333+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:05:31.333+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:05:31.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.113 seconds
[2025-11-20T11:06:04.056+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:06:04.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:06:04.058+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:06:04.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:06:04.074+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:06:04.111+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:06:04.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:06:04.140+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:06:04.140+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:06:04.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.121 seconds
[2025-11-20T11:06:37.892+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:06:37.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:06:37.894+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:06:37.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:06:37.911+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:06:37.945+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:06:37.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:06:37.971+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:06:37.971+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:06:38.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T11:07:10.708+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:07:10.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:07:10.710+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:07:10.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:07:10.729+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:07:10.768+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:07:10.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:07:10.793+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:07:10.793+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:07:10.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.123 seconds
[2025-11-20T11:07:44.665+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:07:44.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:07:44.667+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:07:44.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:07:44.684+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:07:44.721+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:07:44.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:07:44.745+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:07:44.745+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:07:44.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.108 seconds
[2025-11-20T11:08:17.489+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:08:17.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:08:17.492+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:08:17.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:08:17.510+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:08:17.549+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:08:17.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:08:17.582+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:08:17.582+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:08:17.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.137 seconds
[2025-11-20T11:08:51.385+0000] {processor.py:186} INFO - Started process (PID=480) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:08:51.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:08:51.387+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:08:51.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:08:51.405+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:08:51.440+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:08:51.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:08:51.467+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:08:51.467+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:08:51.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.117 seconds
[2025-11-20T11:09:24.191+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:09:24.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:09:24.193+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:09:24.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:09:24.210+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:09:24.242+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:09:24.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:09:24.269+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:09:24.268+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:09:24.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.106 seconds
[2025-11-20T11:09:58.016+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:09:58.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:09:58.019+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:09:58.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:09:58.037+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:09:58.071+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:09:58.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:09:58.096+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:09:58.096+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:09:58.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.108 seconds
[2025-11-20T11:10:30.827+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:10:30.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:10:30.829+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:10:30.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:10:30.847+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:10:30.886+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:10:30.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:10:30.913+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:10:30.913+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:10:30.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.114 seconds
[2025-11-20T11:11:04.765+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:11:04.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:11:04.767+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:11:04.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:11:04.785+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:11:04.822+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:11:04.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:11:04.848+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:11:04.848+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:11:04.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.116 seconds
[2025-11-20T11:11:37.621+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:11:37.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:11:37.623+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:11:37.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:11:37.644+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:11:37.691+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:11:37.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:11:37.724+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:11:37.723+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:11:37.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.146 seconds
[2025-11-20T11:12:10.501+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:12:10.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:12:10.503+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:12:10.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:12:10.522+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:12:10.562+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:12:10.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:12:10.592+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:12:10.591+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:12:10.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.127 seconds
[2025-11-20T11:12:44.403+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:12:44.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:12:44.405+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:12:44.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:12:44.423+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:12:44.462+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:12:44.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:12:44.491+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:12:44.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:12:44.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.129 seconds
[2025-11-20T11:13:17.258+0000] {processor.py:186} INFO - Started process (PID=512) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:13:17.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:13:17.260+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:13:17.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:13:17.278+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:13:17.312+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:13:17.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:13:17.337+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:13:17.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:13:17.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.107 seconds
[2025-11-20T11:13:51.125+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:13:51.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:13:51.127+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:13:51.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:13:51.145+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:13:51.182+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:13:51.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:13:51.213+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:13:51.213+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:13:51.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.126 seconds
[2025-11-20T11:14:24.104+0000] {processor.py:186} INFO - Started process (PID=520) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:14:24.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:14:24.106+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:14:24.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:14:24.121+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:14:24.153+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:14:24.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:14:24.177+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:14:24.177+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:14:24.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.102 seconds
[2025-11-20T11:14:57.886+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:14:57.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:14:57.889+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:14:57.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:14:57.912+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:14:57.951+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:14:57.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:14:57.986+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:14:57.986+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:14:58.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.148 seconds
[2025-11-20T11:15:30.794+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:15:30.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:15:30.797+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:15:30.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:15:30.815+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:15:30.849+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:15:30.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:15:30.877+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:15:30.876+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:15:30.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T11:16:04.663+0000] {processor.py:186} INFO - Started process (PID=532) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:16:04.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:16:04.665+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:16:04.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:16:04.683+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:16:04.732+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:16:04.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:16:04.783+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:16:04.783+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:16:04.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.176 seconds
[2025-11-20T11:16:37.636+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:16:37.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:16:37.638+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:16:37.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:16:37.657+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:16:37.692+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:16:37.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:16:37.730+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:16:37.729+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:16:37.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.139 seconds
[2025-11-20T11:17:10.502+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:17:10.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:17:10.504+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:17:10.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:17:10.522+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:17:10.558+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:17:10.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:17:10.584+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:17:10.584+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:17:10.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.114 seconds
[2025-11-20T11:17:44.564+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:17:44.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:17:44.567+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:17:44.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:17:44.584+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:17:44.617+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:17:44.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:17:44.642+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:17:44.642+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:17:44.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.104 seconds
[2025-11-20T11:18:17.388+0000] {processor.py:186} INFO - Started process (PID=548) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:18:17.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:18:17.390+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:18:17.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:18:17.404+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:18:17.434+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:18:17.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:18:17.457+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:18:17.457+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:18:17.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.093 seconds
[2025-11-20T11:18:51.120+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:18:51.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:18:51.122+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:18:51.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:18:51.140+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:18:51.173+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:18:51.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:18:51.198+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:18:51.198+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:18:51.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.111 seconds
[2025-11-20T11:19:23.933+0000] {processor.py:186} INFO - Started process (PID=556) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:19:23.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:19:23.935+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:19:23.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:19:23.952+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:19:23.985+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:19:23.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:19:24.013+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:19:24.013+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:19:24.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-20T11:19:57.786+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:19:57.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:19:57.788+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:19:57.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:19:57.804+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:19:57.839+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:19:57.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:19:57.875+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:19:57.875+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:19:57.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.134 seconds
[2025-11-20T11:20:30.766+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:20:30.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-20T11:20:30.768+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:20:30.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:20:30.784+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-20T11:20:30.816+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:20:30.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-20T11:20:30.841+0000] {logging_mixin.py:190} INFO - [2025-11-20T11:20:30.841+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-19T00:00:00+00:00, run_after=2025-11-20T00:00:00+00:00
[2025-11-20T11:20:30.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.106 seconds
