[2025-11-10T13:30:48.665+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:30:48.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:30:48.668+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:30:48.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:30:48.687+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:30:48.742+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:30:48.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:30:48.779+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:30:48.779+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:30:48.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.146 seconds
[2025-11-10T13:31:19.034+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:31:19.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:31:19.045+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:31:19.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:31:19.095+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:31:19.144+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:31:19.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:31:19.180+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:31:19.180+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:31:19.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.267 seconds
[2025-11-10T13:31:49.639+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:31:49.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:31:49.641+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:31:49.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:31:49.662+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:31:49.707+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:31:49.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:31:49.742+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:31:49.742+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:31:49.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.136 seconds
[2025-11-10T13:32:20.464+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:32:20.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:32:20.468+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:32:20.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:32:20.497+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:32:20.551+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:32:20.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:32:20.591+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:32:20.591+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:32:20.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.164 seconds
[2025-11-10T13:32:50.937+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:32:50.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:32:50.939+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:32:50.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:32:50.959+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:32:50.999+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:32:50.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:32:51.041+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:32:51.040+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:32:51.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.139 seconds
[2025-11-10T13:33:21.274+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:33:21.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:33:21.277+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:33:21.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:33:21.302+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:33:21.364+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:33:21.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:33:21.410+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:33:21.410+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:33:21.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.188 seconds
[2025-11-10T13:33:51.854+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:33:51.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:33:51.856+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:33:51.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:33:51.878+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:33:51.925+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:33:51.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:33:51.967+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:33:51.967+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:33:52.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.158 seconds
[2025-11-10T13:34:22.132+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:34:22.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:34:22.141+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:34:22.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:34:22.168+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:34:22.228+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:34:22.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:34:22.280+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:34:22.280+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:34:22.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.209 seconds
[2025-11-10T13:34:53.000+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:34:53.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:34:53.004+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:34:53.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:34:53.032+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:34:53.100+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:34:53.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:34:53.154+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:34:53.153+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:34:53.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.204 seconds
[2025-11-10T13:35:23.336+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:35:23.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:35:23.338+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:35:23.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:35:23.356+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:35:23.397+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:35:23.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:35:23.430+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:35:23.429+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:35:23.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.125 seconds
[2025-11-10T13:35:53.539+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:35:53.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:35:53.542+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:35:53.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:35:53.565+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:35:53.609+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:35:53.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:35:53.642+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:35:53.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:35:53.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.151 seconds
[2025-11-10T13:36:27.224+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:36:27.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:36:27.226+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:36:27.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:36:27.254+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:36:27.305+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:36:27.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:36:27.357+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:36:27.357+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:36:27.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.197 seconds
[2025-11-10T13:36:59.551+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:36:59.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:36:59.554+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:36:59.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:36:59.577+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:36:59.642+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:36:59.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:36:59.715+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:36:59.714+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:36:59.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.249 seconds
[2025-11-10T13:37:32.019+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:37:32.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:37:32.022+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:37:32.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:37:32.044+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:37:32.101+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:37:32.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:37:32.144+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:37:32.144+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:37:32.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.168 seconds
[2025-11-10T13:38:04.487+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:38:04.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:38:04.491+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:38:04.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:38:04.518+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:38:04.567+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:38:04.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:38:04.609+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:38:04.609+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:38:04.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.191 seconds
[2025-11-10T13:38:37.987+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:38:37.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:38:37.990+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:38:37.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:38:38.015+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:38:38.067+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:38:38.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:38:38.107+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:38:38.107+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:38:38.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.175 seconds
[2025-11-10T13:39:08.860+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:39:08.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:39:08.863+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:39:08.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:39:08.885+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:39:08.926+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:39:08.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:39:08.975+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:39:08.975+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:39:09.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.166 seconds
[2025-11-10T13:39:39.599+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:39:39.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:39:39.602+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:39:39.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:39:39.636+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:39:39.720+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:39:39.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:39:39.773+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:39:39.772+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:39:39.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.225 seconds
[2025-11-10T13:40:10.783+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:40:10.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:40:10.786+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:40:10.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:40:10.813+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:40:10.876+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:40:10.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:40:10.923+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:40:10.922+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:40:10.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.194 seconds
[2025-11-10T13:40:41.321+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:40:41.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:40:41.323+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:40:41.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:40:41.348+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:40:41.388+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:40:41.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:40:41.417+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:40:41.417+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:40:41.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.135 seconds
[2025-11-10T13:41:11.510+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:41:11.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:41:11.513+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:41:11.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:41:11.535+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:41:11.581+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:41:11.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:41:11.618+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:41:11.618+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:41:11.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.143 seconds
[2025-11-10T13:41:42.113+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:41:42.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:41:42.116+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:41:42.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:41:42.139+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:41:42.191+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:41:42.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:41:42.228+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:41:42.227+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:41:42.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.152 seconds
[2025-11-10T13:42:12.424+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:42:12.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:42:12.428+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:42:12.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:42:12.464+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:42:12.522+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:42:12.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:42:12.568+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:42:12.568+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:42:12.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.201 seconds
[2025-11-10T13:42:42.941+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:42:42.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:42:42.943+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:42:42.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:42:42.966+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:42:43.013+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:42:43.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:42:43.052+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:42:43.051+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:42:43.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.145 seconds
[2025-11-10T13:43:13.283+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:43:13.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:43:13.285+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:43:13.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:43:13.307+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:43:13.353+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:43:13.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:43:13.387+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:43:13.387+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:43:13.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.151 seconds
[2025-11-10T13:43:43.607+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:43:43.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:43:43.610+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:43:43.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:43:43.639+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:43:43.690+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:43:43.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:43:43.742+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:43:43.741+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:43:43.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.201 seconds
[2025-11-10T13:44:14.321+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:44:14.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:44:14.323+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:44:14.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:44:14.351+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:44:14.434+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:44:14.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:44:14.508+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:44:14.508+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:44:14.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.255 seconds
[2025-11-10T13:44:44.695+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:44:44.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:44:44.698+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:44:44.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:44:44.730+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:44:44.785+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:44:44.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:44:44.817+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:44:44.817+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:44:44.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.155 seconds
[2025-11-10T13:45:15.066+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:45:15.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:45:15.068+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:45:15.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:45:15.090+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:45:15.129+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:45:15.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:45:15.161+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:45:15.161+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:45:15.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.128 seconds
[2025-11-10T13:45:45.333+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:45:45.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:45:45.336+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:45:45.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:45:45.362+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:45:45.411+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:45:45.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:45:45.450+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:45:45.449+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:45:45.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.156 seconds
[2025-11-10T13:46:15.738+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:46:15.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:46:15.741+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:46:15.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:46:15.763+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:46:15.808+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:46:15.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:46:15.856+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:46:15.855+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:46:15.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.162 seconds
[2025-11-10T13:46:48.382+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:46:48.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:46:48.384+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:46:48.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:46:48.404+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:46:48.470+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:46:48.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:46:48.505+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:46:48.505+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:46:48.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.160 seconds
[2025-11-10T13:47:21.597+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:47:21.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:47:21.599+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:47:21.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:47:21.622+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:47:21.664+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:47:21.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:47:21.697+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:47:21.697+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:47:21.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.138 seconds
[2025-11-10T13:47:53.943+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:47:53.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:47:53.945+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:47:53.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:47:53.969+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:47:54.011+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:47:54.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:47:54.050+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:47:54.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:47:54.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.153 seconds
[2025-11-10T13:48:27.374+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:48:27.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:48:27.377+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:48:27.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:48:27.404+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:48:27.458+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:48:27.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:48:27.501+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:48:27.501+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:48:27.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-10T13:48:59.757+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:48:59.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:48:59.760+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:48:59.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:48:59.792+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:48:59.844+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:48:59.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:48:59.889+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:48:59.889+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:48:59.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-10T13:49:32.323+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:49:32.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:49:32.326+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:49:32.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:49:32.345+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:49:32.385+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:49:32.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:49:32.419+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:49:32.419+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:49:32.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.124 seconds
[2025-11-10T13:50:04.652+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:50:04.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:50:04.656+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:50:04.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:50:04.688+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:50:04.752+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:50:04.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:50:04.796+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:50:04.796+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:50:04.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.202 seconds
[2025-11-10T13:50:38.180+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:50:38.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:50:38.184+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:50:38.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:50:38.212+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:50:38.257+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:50:38.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:50:38.291+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:50:38.291+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:50:38.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.154 seconds
[2025-11-10T13:51:10.707+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:51:10.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:51:10.710+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:51:10.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:51:10.732+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:51:10.775+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:51:10.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:51:10.809+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:51:10.809+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:51:10.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.136 seconds
[2025-11-10T13:51:43.280+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:51:43.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:51:43.282+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:51:43.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:51:43.312+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:51:43.368+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:51:43.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:51:43.407+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:51:43.406+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:51:43.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.172 seconds
[2025-11-10T13:52:15.728+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:52:15.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:52:15.735+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:52:15.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:52:15.784+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:52:15.856+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:52:15.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:52:15.908+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:52:15.907+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:52:15.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.231 seconds
[2025-11-10T13:52:48.247+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:52:48.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:52:48.250+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:52:48.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:52:48.272+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:52:48.317+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:52:48.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:52:48.349+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:52:48.348+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:52:48.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.144 seconds
[2025-11-10T13:53:21.648+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:53:21.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:53:21.650+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:53:21.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:53:21.682+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:53:21.731+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:53:21.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:53:21.773+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:53:21.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:53:21.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-10T13:53:54.251+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:53:54.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:53:54.254+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:53:54.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:53:54.276+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:53:54.320+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:53:54.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:53:54.352+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:53:54.352+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:53:54.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.134 seconds
[2025-11-10T13:54:26.690+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:54:26.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:54:26.692+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:54:26.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:54:26.713+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:54:26.754+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:54:26.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:54:26.788+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:54:26.788+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:54:26.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.131 seconds
[2025-11-10T13:54:59.070+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:54:59.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:54:59.072+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:54:59.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:54:59.094+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:54:59.138+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:54:59.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:54:59.171+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:54:59.171+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:54:59.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.148 seconds
[2025-11-10T13:55:32.438+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:55:32.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:55:32.441+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:55:32.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:55:32.462+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:55:32.515+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:55:32.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:55:32.565+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:55:32.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:55:32.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.172 seconds
[2025-11-10T13:56:04.962+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:56:04.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:56:04.965+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:56:04.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:56:04.997+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:56:05.048+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:56:05.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:56:05.099+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:56:05.099+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:56:05.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.195 seconds
[2025-11-10T13:56:37.728+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:56:37.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:56:37.731+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:56:37.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:56:37.764+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:56:37.818+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:56:37.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:56:37.863+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:56:37.863+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:56:37.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.194 seconds
[2025-11-10T13:57:10.141+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:57:10.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:57:10.144+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:57:10.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:57:10.165+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:57:10.213+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:57:10.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:57:10.259+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:57:10.258+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:57:10.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.155 seconds
[2025-11-10T13:57:43.556+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:57:43.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:57:43.558+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:57:43.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:57:43.588+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:57:43.674+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:57:43.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:57:43.729+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:57:43.728+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:57:43.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.226 seconds
[2025-11-10T13:58:16.211+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:58:16.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:58:16.213+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:58:16.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:58:16.232+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:58:16.269+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:58:16.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:58:16.299+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:58:16.298+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:58:16.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.115 seconds
[2025-11-10T13:58:48.467+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:58:48.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:58:48.471+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:58:48.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:58:48.500+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:58:48.551+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:58:48.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:58:48.590+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:58:48.589+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:58:48.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.167 seconds
[2025-11-10T13:59:22.057+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:59:22.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:59:22.059+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:59:22.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:59:22.080+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:59:22.125+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:59:22.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:59:22.157+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:59:22.157+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:59:22.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.140 seconds
[2025-11-10T13:59:54.506+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:59:54.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T13:59:54.511+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:59:54.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:59:54.544+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T13:59:54.594+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:59:54.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T13:59:54.631+0000] {logging_mixin.py:190} INFO - [2025-11-10T13:59:54.631+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T13:59:54.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-10T14:00:27.174+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:00:27.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:00:27.190+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:00:27.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:00:27.222+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:00:27.280+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:00:27.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:00:27.337+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:00:27.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:00:27.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.212 seconds
[2025-11-10T14:01:00.517+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:01:00.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:01:00.520+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:01:00.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:01:00.545+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:01:00.607+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:01:00.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:01:00.666+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:01:00.666+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:01:00.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.256 seconds
[2025-11-10T14:01:32.780+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:01:32.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:01:32.785+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:01:32.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:01:32.818+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:01:32.884+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:01:32.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:01:32.930+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:01:32.929+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:01:32.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.190 seconds
[2025-11-10T14:02:05.112+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:02:05.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:02:05.114+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:02:05.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:02:05.134+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:02:05.176+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:02:05.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:02:05.211+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:02:05.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:02:05.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-10T14:02:37.558+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:02:37.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:02:37.559+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:02:37.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:02:37.578+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:02:37.618+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:02:37.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:02:37.646+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:02:37.646+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:02:37.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.116 seconds
[2025-11-10T14:03:10.943+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:03:10.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:03:10.946+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:03:10.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:03:10.978+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:03:11.059+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:03:11.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:03:11.104+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:03:11.104+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:03:11.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.209 seconds
[2025-11-10T14:03:43.165+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:03:43.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:03:43.167+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:03:43.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:03:43.186+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:03:43.225+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:03:43.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:03:43.259+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:03:43.259+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:03:43.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.125 seconds
[2025-11-10T14:04:15.501+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:04:15.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:04:15.503+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:04:15.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:04:15.524+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:04:15.570+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:04:15.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:04:15.603+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:04:15.603+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:04:15.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.141 seconds
[2025-11-10T14:04:48.857+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:04:48.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:04:48.859+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:04:48.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:04:48.879+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:04:48.920+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:04:48.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:04:48.958+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:04:48.957+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:04:48.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.134 seconds
[2025-11-10T14:05:21.289+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:05:21.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:05:21.293+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:05:21.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:05:21.315+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:05:21.351+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:05:21.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:05:21.381+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:05:21.381+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:05:21.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-10T14:05:54.659+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:05:54.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:05:54.661+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:05:54.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:05:54.681+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:05:54.719+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:05:54.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:05:54.752+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:05:54.752+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:05:54.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-10T14:06:27.001+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:06:27.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:06:27.003+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:06:27.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:06:27.024+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:06:27.065+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:06:27.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:06:27.097+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:06:27.097+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:06:27.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.135 seconds
[2025-11-10T14:06:59.346+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:06:59.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:06:59.349+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:06:59.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:06:59.369+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:06:59.408+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:06:59.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:06:59.439+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:06:59.439+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:06:59.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.127 seconds
[2025-11-10T14:07:32.677+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:07:32.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:07:32.679+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:07:32.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:07:32.701+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:07:32.740+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:07:32.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:07:32.770+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:07:32.770+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:07:32.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.128 seconds
[2025-11-10T14:08:04.992+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:08:04.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:08:04.994+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:08:04.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:08:05.016+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:08:05.056+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:08:05.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:08:05.086+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:08:05.086+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:08:05.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.129 seconds
[2025-11-10T14:08:37.302+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:08:37.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:08:37.304+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:08:37.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:08:37.326+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:08:37.372+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:08:37.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:08:37.404+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:08:37.404+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:08:37.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.142 seconds
[2025-11-10T14:09:10.662+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:09:10.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:09:10.665+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:09:10.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:09:10.696+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:09:10.751+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:09:10.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:09:10.783+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:09:10.783+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:09:10.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.162 seconds
[2025-11-10T14:09:43.038+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:09:43.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:09:43.040+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:09:43.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:09:43.060+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:09:43.102+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:09:43.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:09:43.134+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:09:43.134+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:09:43.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-10T14:10:16.406+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:10:16.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:10:16.409+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:10:16.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:10:16.451+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:10:16.525+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:10:16.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:10:16.565+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:10:16.565+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:10:16.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.198 seconds
[2025-11-10T14:10:48.837+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:10:48.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:10:48.840+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:10:48.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:10:48.860+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:10:48.908+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:10:48.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:10:48.949+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:10:48.949+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:10:48.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.151 seconds
[2025-11-10T14:11:21.200+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:11:21.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:11:21.202+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:11:21.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:11:21.222+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:11:21.260+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:11:21.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:11:21.300+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:11:21.300+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:11:21.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.145 seconds
[2025-11-10T14:11:54.694+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:11:54.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:11:54.696+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:11:54.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:11:54.723+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:11:54.770+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:11:54.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:11:54.812+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:11:54.812+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:11:54.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.165 seconds
[2025-11-10T14:12:27.086+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:12:27.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:12:27.089+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:12:27.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:12:27.109+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:12:27.149+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:12:27.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:12:27.180+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:12:27.180+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:12:27.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.134 seconds
[2025-11-10T14:12:59.428+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:12:59.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:12:59.430+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:12:59.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:12:59.456+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:12:59.495+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:12:59.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:12:59.529+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:12:59.529+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:12:59.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.141 seconds
[2025-11-10T14:13:32.811+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:13:32.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:13:32.814+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:13:32.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:13:32.836+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:13:32.887+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:13:32.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:13:32.918+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:13:32.918+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:13:32.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.146 seconds
[2025-11-10T14:14:05.171+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:14:05.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:14:05.174+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:14:05.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:14:05.195+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:14:05.233+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:14:05.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:14:05.264+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:14:05.264+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:14:05.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-10T14:14:37.499+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:14:37.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:14:37.501+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:14:37.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:14:37.523+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:14:37.563+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:14:37.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:14:37.597+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:14:37.596+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:14:37.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.148 seconds
[2025-11-10T14:15:10.846+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:15:10.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:15:10.848+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:15:10.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:15:10.871+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:15:10.926+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:15:10.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:15:10.961+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:15:10.961+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:15:10.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.146 seconds
[2025-11-10T14:15:43.178+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:15:43.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:15:43.181+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:15:43.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:15:43.203+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:15:43.242+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:15:43.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:15:43.274+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:15:43.273+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:15:43.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.130 seconds
[2025-11-10T14:16:16.542+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:16:16.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:16:16.545+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:16:16.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:16:16.566+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:16:16.608+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:16:16.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:16:16.649+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:16:16.649+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:16:16.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.171 seconds
[2025-11-10T14:16:48.931+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:16:48.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:16:48.933+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:16:48.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:16:48.954+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:16:49.000+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:16:49.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:16:49.033+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:16:49.033+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:16:49.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.148 seconds
[2025-11-10T14:17:21.409+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:17:21.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:17:21.412+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:17:21.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:17:21.430+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:17:21.465+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:17:21.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:17:21.493+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:17:21.493+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:17:21.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.113 seconds
[2025-11-10T14:17:53.755+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:17:53.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:17:53.757+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:17:53.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:17:53.777+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:17:53.816+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:17:53.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:17:53.847+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:17:53.847+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:17:53.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.127 seconds
[2025-11-10T14:18:27.183+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:18:27.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:18:27.185+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:18:27.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:18:27.207+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:18:27.242+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:18:27.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:18:27.272+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:18:27.272+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:18:27.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.131 seconds
[2025-11-10T14:18:59.659+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:18:59.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:18:59.661+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:18:59.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:18:59.679+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:18:59.719+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:18:59.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:18:59.747+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:18:59.747+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:18:59.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.116 seconds
[2025-11-10T14:19:32.112+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:19:32.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:19:32.114+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:19:32.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:19:32.134+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:19:32.174+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:19:32.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:19:32.204+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:19:32.204+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:19:32.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.133 seconds
[2025-11-10T14:20:05.484+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:20:05.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:20:05.486+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:20:05.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:20:05.504+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:20:05.548+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:20:05.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:20:05.579+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:20:05.579+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:20:05.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.139 seconds
[2025-11-10T14:20:37.931+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:20:37.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:20:37.933+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:20:37.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:20:37.951+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:20:37.985+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:20:37.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:20:38.012+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:20:38.012+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:20:38.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.116 seconds
[2025-11-10T14:21:10.145+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:21:10.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:21:10.148+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:21:10.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:21:10.167+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:21:10.206+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:21:10.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:21:10.236+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:21:10.236+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:21:10.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.124 seconds
[2025-11-10T14:21:43.675+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:21:43.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:21:43.677+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:21:43.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:21:43.698+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:21:43.739+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:21:43.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:21:43.770+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:21:43.770+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:21:43.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.135 seconds
[2025-11-10T14:32:10.706+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:32:10.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:32:10.713+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:32:10.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:32:10.757+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:32:10.992+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:32:10.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:32:11.075+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:32:11.075+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:32:11.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.445 seconds
[2025-11-10T14:32:41.244+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:32:41.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:32:41.247+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:32:41.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:32:41.272+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:32:41.332+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:32:41.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:32:41.378+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:32:41.378+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:32:41.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.174 seconds
[2025-11-10T14:33:12.306+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:33:12.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-10T14:33:12.308+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:33:12.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:33:12.332+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-10T14:33:12.376+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:33:12.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-10T14:33:12.411+0000] {logging_mixin.py:190} INFO - [2025-11-10T14:33:12.411+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-09T00:00:00+00:00, run_after=2025-11-10T00:00:00+00:00
[2025-11-10T14:33:12.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.147 seconds
