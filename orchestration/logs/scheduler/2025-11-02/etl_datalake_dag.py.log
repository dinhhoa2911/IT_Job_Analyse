[2025-11-02T09:12:48.781+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:12:48.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:12:48.796+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:12:48.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:12:48.853+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:12:48.986+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:12:48.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:12:49.145+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:12:49.140+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:12:49.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.496 seconds
[2025-11-02T09:13:19.623+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:13:19.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:13:19.630+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:13:19.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:13:19.673+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:13:19.766+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:13:19.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:13:19.858+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:13:19.857+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:13:19.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.325 seconds
[2025-11-02T09:13:50.730+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:13:50.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:13:50.733+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:13:50.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:13:50.762+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:13:50.820+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:13:50.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:13:50.865+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:13:50.864+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:13:50.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.184 seconds
[2025-11-02T09:14:21.401+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:14:21.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:14:21.403+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:14:21.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:14:21.429+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:14:21.479+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:14:21.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:14:21.531+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:14:21.531+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:14:21.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.188 seconds
[2025-11-02T09:14:52.110+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:14:52.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:14:52.113+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:14:52.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:14:52.155+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:14:52.290+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:14:52.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:14:52.414+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:14:52.414+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:14:52.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.429 seconds
[2025-11-02T09:15:22.695+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:15:22.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:15:22.700+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:15:22.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:15:22.749+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:15:22.838+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:15:22.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:15:22.927+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:15:22.926+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:15:22.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.318 seconds
[2025-11-02T09:15:53.312+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:15:53.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:15:53.315+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:15:53.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:15:53.346+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:15:53.405+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:15:53.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:15:53.452+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:15:53.452+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:15:53.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.188 seconds
[2025-11-02T09:16:23.912+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:16:23.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:16:23.915+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:16:23.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:16:23.952+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:16:24.011+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:16:24.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:16:24.058+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:16:24.058+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:16:24.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.232 seconds
[2025-11-02T09:16:55.769+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:16:55.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:16:55.773+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:16:55.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:16:55.807+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:16:55.887+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:16:55.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:16:55.960+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:16:55.960+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:16:56.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.245 seconds
[2025-11-02T09:17:26.724+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:17:26.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:17:26.728+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:17:26.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:17:26.765+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:17:26.835+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:17:26.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:17:26.885+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:17:26.884+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:17:26.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.245 seconds
[2025-11-02T09:17:57.859+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:17:57.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:17:57.861+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:17:57.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:17:57.887+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:17:57.939+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:17:57.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:17:57.978+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:17:57.978+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:17:58.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.197 seconds
[2025-11-02T09:18:29.009+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:18:29.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:18:29.012+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:18:29.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:18:29.041+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:18:29.096+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:18:29.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:18:29.136+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:18:29.136+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:18:29.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.191 seconds
[2025-11-02T09:18:59.321+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:18:59.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:18:59.326+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:18:59.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:18:59.359+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:18:59.442+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:18:59.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:18:59.513+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:18:59.512+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:18:59.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.269 seconds
[2025-11-02T09:19:29.835+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:19:29.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:19:29.838+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:19:29.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:19:29.863+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:19:29.917+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:19:29.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:19:29.959+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:19:29.959+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:19:30.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-02T09:20:00.824+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:20:00.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:20:00.827+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:20:00.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:20:00.855+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:20:00.912+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:20:00.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:20:00.956+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:20:00.956+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:20:01.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.201 seconds
[2025-11-02T09:20:31.997+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:20:31.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:20:32.004+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:20:32.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:20:32.075+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:20:32.198+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:20:32.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:20:32.320+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:20:32.320+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:20:32.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.415 seconds
[2025-11-02T09:21:03.302+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:21:03.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:21:03.305+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:21:03.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:21:03.338+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:21:03.411+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:21:03.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:21:03.473+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:21:03.472+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:21:03.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.331 seconds
[2025-11-02T09:21:34.201+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:21:34.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:21:34.205+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:21:34.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:21:34.241+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:21:34.318+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:21:34.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:21:34.384+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:21:34.383+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:21:34.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.271 seconds
[2025-11-02T09:22:05.261+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:22:05.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:22:05.266+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:22:05.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:22:05.318+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:22:05.441+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:22:05.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:22:05.533+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:22:05.533+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:22:05.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.368 seconds
[2025-11-02T09:22:36.247+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:22:36.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:22:36.250+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:22:36.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:22:36.285+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:22:36.349+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:22:36.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:22:36.395+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:22:36.394+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:22:36.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.198 seconds
[2025-11-02T09:23:07.337+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:23:07.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:23:07.339+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:23:07.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:23:07.365+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:23:07.420+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:23:07.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:23:07.564+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:23:07.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:23:07.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.331 seconds
[2025-11-02T09:23:38.679+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:23:38.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:23:38.684+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:23:38.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:23:38.722+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:23:38.813+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:23:38.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:23:38.878+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:23:38.877+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:23:38.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.281 seconds
[2025-11-02T09:24:09.289+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:24:09.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:24:09.291+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:24:09.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:24:09.318+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:24:09.369+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:24:09.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:24:09.412+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:24:09.411+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:24:09.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.170 seconds
[2025-11-02T09:24:39.626+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:24:39.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:24:39.630+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:24:39.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:24:39.658+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:24:39.722+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:24:39.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:24:39.765+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:24:39.765+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:24:39.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.228 seconds
[2025-11-02T09:25:10.429+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:25:10.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:25:10.433+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:25:10.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:25:10.477+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:25:10.547+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:25:10.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:25:10.595+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:25:10.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:25:10.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.233 seconds
[2025-11-02T09:25:41.120+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:25:41.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:25:41.122+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:25:41.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:25:41.146+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:25:41.194+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:25:41.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:25:41.237+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:25:41.237+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:25:41.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.166 seconds
[2025-11-02T09:26:11.997+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:26:11.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:26:12.001+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:26:12.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:26:12.032+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:26:12.113+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:26:12.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:26:12.203+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:26:12.203+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:26:12.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.298 seconds
[2025-11-02T09:26:43.112+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:26:43.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:26:43.114+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:26:43.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:26:43.144+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:26:43.255+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:26:43.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:26:43.304+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:26:43.304+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:26:43.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.252 seconds
[2025-11-02T09:27:14.346+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:27:14.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:27:14.348+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:27:14.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:27:14.373+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:27:14.420+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:27:14.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:27:14.464+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:27:14.464+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:27:14.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.162 seconds
[2025-11-02T09:27:45.102+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:27:45.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:27:45.105+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:27:45.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:27:45.129+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:27:45.175+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:27:45.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:27:45.247+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:27:45.247+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:27:45.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.199 seconds
[2025-11-02T09:28:16.223+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:28:16.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:28:16.227+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:28:16.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:28:16.271+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:28:16.342+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:28:16.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:28:16.396+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:28:16.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:28:16.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.250 seconds
[2025-11-02T09:28:47.499+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:28:47.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:28:47.503+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:28:47.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:28:47.544+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:28:47.604+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:28:47.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:28:47.650+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:28:47.650+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:28:47.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.225 seconds
[2025-11-02T09:29:18.241+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:29:18.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:29:18.244+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:29:18.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:29:18.287+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:29:18.367+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:29:18.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:29:18.423+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:29:18.423+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:29:18.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.241 seconds
[2025-11-02T09:29:49.167+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:29:49.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:29:49.170+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:29:49.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:29:49.208+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:29:49.283+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:29:49.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:29:49.336+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:29:49.335+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:29:49.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.237 seconds
[2025-11-02T09:30:20.350+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:30:20.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:30:20.352+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:30:20.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:30:20.379+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:30:20.430+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:30:20.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:30:20.469+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:30:20.469+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:30:20.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.167 seconds
[2025-11-02T09:30:51.124+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:30:51.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:30:51.127+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:30:51.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:30:51.151+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:30:51.206+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:30:51.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:30:51.253+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:30:51.253+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:30:51.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.177 seconds
[2025-11-02T09:31:22.277+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:31:22.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:31:22.281+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:31:22.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:31:22.311+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:31:22.363+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:31:22.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:31:22.403+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:31:22.403+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:31:22.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.164 seconds
[2025-11-02T09:31:53.466+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:31:53.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:31:53.471+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:31:53.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:31:53.503+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:31:53.572+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:31:53.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:31:53.633+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:31:53.633+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:31:53.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.235 seconds
[2025-11-02T09:32:23.736+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:32:23.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:32:23.738+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:32:23.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:32:23.759+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:32:23.801+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:32:23.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:32:23.837+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:32:23.836+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:32:23.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.142 seconds
[2025-11-02T09:32:54.641+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:32:54.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:32:54.644+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:32:54.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:32:54.677+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:32:54.740+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:32:54.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:32:54.782+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:32:54.782+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:32:54.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.193 seconds
[2025-11-02T09:33:25.800+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:33:25.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:33:25.802+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:33:25.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:33:25.828+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:33:25.879+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:33:25.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:33:25.942+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:33:25.942+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:33:25.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.193 seconds
[2025-11-02T09:33:56.892+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:33:56.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:33:56.895+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:33:56.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:33:56.924+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:33:56.996+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:33:56.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:33:57.074+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:33:57.074+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:33:57.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.256 seconds
[2025-11-02T09:34:27.650+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:34:27.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:34:27.654+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:34:27.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:34:27.691+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:34:27.743+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:34:27.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:34:27.781+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:34:27.780+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:34:27.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.182 seconds
[2025-11-02T09:34:58.816+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:34:58.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:34:58.818+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:34:58.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:34:58.850+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:34:58.915+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:34:58.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:34:58.956+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:34:58.956+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:34:59.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.196 seconds
[2025-11-02T09:35:29.892+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:35:29.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:35:29.897+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:35:29.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:35:29.929+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:35:29.998+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:35:29.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:35:30.067+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:35:30.067+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:35:30.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.295 seconds
[2025-11-02T09:36:01.201+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:36:01.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:36:01.205+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:36:01.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:36:01.233+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:36:01.282+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:36:01.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:36:01.333+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:36:01.332+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:36:01.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.190 seconds
[2025-11-02T09:36:32.226+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:36:32.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:36:32.229+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:36:32.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:36:32.255+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:36:32.305+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:36:32.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:36:32.350+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:36:32.350+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:36:32.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.184 seconds
[2025-11-02T09:37:02.940+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:37:02.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:37:02.943+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:37:02.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:37:02.968+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:37:03.046+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:37:03.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:37:03.094+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:37:03.094+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:37:03.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.215 seconds
[2025-11-02T09:37:34.099+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:37:34.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:37:34.105+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:37:34.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:37:34.139+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:37:34.202+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:37:34.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:37:34.249+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:37:34.249+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:37:34.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.211 seconds
[2025-11-02T09:38:04.549+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:38:04.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:38:04.551+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:38:04.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:38:04.580+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:38:04.631+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:38:04.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:38:04.677+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:38:04.676+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:38:04.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.191 seconds
[2025-11-02T09:38:35.538+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:38:35.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:38:35.543+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:38:35.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:38:35.575+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:38:35.650+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:38:35.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:38:35.713+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:38:35.712+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:38:35.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.253 seconds
[2025-11-02T09:39:05.919+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:39:05.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:39:05.922+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:39:05.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:39:05.946+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:39:06.020+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:39:06.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:39:06.065+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:39:06.065+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:39:06.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.208 seconds
[2025-11-02T09:39:36.781+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:39:36.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:39:36.783+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:39:36.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:39:36.813+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:39:36.872+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:39:36.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:39:36.938+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:39:36.937+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:39:36.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.212 seconds
[2025-11-02T09:40:07.217+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:40:07.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:40:07.220+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:40:07.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:40:07.251+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:40:07.313+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:40:07.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:40:07.378+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:40:07.378+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:40:07.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.304 seconds
[2025-11-02T09:40:37.812+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:40:37.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:40:37.815+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:40:37.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:40:37.850+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:40:37.918+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:40:37.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:40:37.975+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:40:37.975+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:40:38.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.224 seconds
[2025-11-02T09:41:08.235+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:41:08.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:41:08.238+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:41:08.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:41:08.275+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:41:08.374+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:41:08.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:41:08.441+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:41:08.441+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:41:08.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.290 seconds
[2025-11-02T09:41:39.310+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:41:39.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:41:39.314+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:41:39.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:41:39.347+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:41:39.448+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:41:39.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:41:39.500+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:41:39.500+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:41:39.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.260 seconds
[2025-11-02T09:42:10.242+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:42:10.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:42:10.244+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:42:10.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:42:10.268+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:42:10.326+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:42:10.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:42:10.400+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:42:10.400+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:42:10.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.227 seconds
[2025-11-02T09:42:41.339+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:42:41.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:42:41.344+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:42:41.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:42:41.373+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:42:41.420+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:42:41.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:42:41.462+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:42:41.462+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:42:41.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.183 seconds
[2025-11-02T09:43:12.525+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:43:12.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:43:12.528+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:43:12.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:43:12.564+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:43:12.617+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:43:12.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:43:12.656+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:43:12.656+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:43:12.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.190 seconds
[2025-11-02T09:43:42.830+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:43:42.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:43:42.835+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:43:42.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:43:42.866+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:43:42.922+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:43:42.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:43:42.979+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:43:42.978+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:43:43.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.235 seconds
[2025-11-02T09:44:14.404+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:44:14.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:44:14.409+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:44:14.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:44:14.467+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:44:14.584+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:44:14.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:44:14.648+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:44:14.648+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:44:14.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.306 seconds
[2025-11-02T09:44:45.621+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:44:45.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:44:45.624+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:44:45.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:44:45.649+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:44:45.696+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:44:45.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:44:45.735+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:44:45.735+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:44:45.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.160 seconds
[2025-11-02T09:45:17.077+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:45:17.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:45:17.080+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:45:17.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:45:17.108+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:45:17.189+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:45:17.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:45:17.249+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:45:17.249+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:45:17.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.237 seconds
[2025-11-02T09:45:48.664+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:45:48.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:45:48.666+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:45:48.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:45:48.708+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:45:48.787+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:45:48.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:45:48.848+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:45:48.848+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:45:49.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 1.203 seconds
[2025-11-02T09:46:20.219+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:46:20.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:46:20.222+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:46:20.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:46:20.256+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:46:20.321+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:46:20.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:46:20.399+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:46:20.399+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:46:20.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.242 seconds
[2025-11-02T09:46:50.547+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:46:50.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:46:50.550+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:46:50.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:46:50.579+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:46:50.635+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:46:50.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:46:50.683+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:46:50.683+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:46:50.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.195 seconds
[2025-11-02T09:47:21.942+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:47:21.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:47:21.945+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:47:21.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:47:21.968+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:47:22.011+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:47:22.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:47:22.043+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:47:22.043+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:47:22.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.133 seconds
[2025-11-02T09:47:54.263+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:47:54.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:47:54.267+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:47:54.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:47:54.309+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:47:54.475+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:47:54.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:47:54.551+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:47:54.551+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:47:54.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.370 seconds
[2025-11-02T09:48:25.407+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:48:25.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:48:25.410+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:48:25.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:48:25.433+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:48:25.480+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:48:25.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:48:25.517+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:48:25.517+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:48:25.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.145 seconds
[2025-11-02T09:48:56.453+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:48:56.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:48:56.456+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:48:56.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:48:56.489+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:48:56.555+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:48:56.555+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:48:56.607+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:48:56.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:48:56.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.204 seconds
[2025-11-02T09:49:27.748+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:49:27.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:49:27.752+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:49:27.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:49:27.793+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:49:27.859+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:49:27.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:49:27.914+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:49:27.914+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:49:27.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.223 seconds
[2025-11-02T09:49:59.018+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:49:59.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:49:59.021+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:49:59.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:49:59.047+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:49:59.097+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:49:59.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:49:59.138+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:49:59.138+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:49:59.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.169 seconds
[2025-11-02T09:50:31.347+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:50:31.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:50:31.351+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:50:31.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:50:31.408+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:50:31.486+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:50:31.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:50:31.539+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:50:31.539+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:50:31.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.257 seconds
[2025-11-02T09:51:03.223+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:51:03.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:51:03.227+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:51:03.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:51:03.258+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:51:03.322+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:51:03.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:51:03.372+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:51:03.372+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:51:03.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.207 seconds
[2025-11-02T09:51:33.689+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:51:33.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:51:33.691+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:51:33.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:51:33.715+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:51:33.762+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:51:33.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:51:33.803+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:51:33.803+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:51:33.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.158 seconds
[2025-11-02T09:52:04.946+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:52:04.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:52:04.949+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:52:04.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:52:04.982+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:52:05.044+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:52:05.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:52:05.083+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:52:05.083+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:52:05.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.207 seconds
[2025-11-02T09:52:36.678+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:52:36.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:52:36.681+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:52:36.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:52:36.711+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:52:36.779+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:52:36.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:52:36.835+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:52:36.835+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:52:36.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.225 seconds
[2025-11-02T09:53:07.776+0000] {processor.py:186} INFO - Started process (PID=352) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:53:07.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:53:07.779+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:53:07.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:53:07.814+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:53:07.888+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:53:07.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:53:07.940+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:53:07.940+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:53:07.995+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.229 seconds
[2025-11-02T09:53:39.204+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:53:39.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:53:39.207+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:53:39.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:53:39.238+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:53:39.301+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:53:39.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:53:39.351+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:53:39.350+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:53:39.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.205 seconds
[2025-11-02T09:54:10.630+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:54:10.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:54:10.634+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:54:10.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:54:10.656+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:54:10.707+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:54:10.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:54:10.749+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:54:10.749+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:54:10.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.180 seconds
[2025-11-02T09:54:41.943+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:54:41.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:54:41.947+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:54:41.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:54:41.982+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:54:42.048+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:54:42.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:54:42.103+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:54:42.103+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:54:42.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.215 seconds
[2025-11-02T09:55:13.287+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:55:13.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:55:13.290+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:55:13.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:55:13.320+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:55:13.370+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:55:13.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:55:13.413+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:55:13.413+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:55:13.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.173 seconds
[2025-11-02T09:55:45.673+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:55:45.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:55:45.675+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:55:45.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:55:45.701+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:55:45.748+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:55:45.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:55:45.784+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:55:45.784+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:55:45.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.151 seconds
[2025-11-02T09:56:16.813+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:56:16.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:56:16.818+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:56:16.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:56:16.857+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:56:16.928+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:56:16.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:56:16.983+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:56:16.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:56:17.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.241 seconds
[2025-11-02T09:56:48.615+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:56:48.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:56:48.620+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:56:48.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:56:48.674+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:56:48.792+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:56:48.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:56:48.855+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:56:48.855+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:56:48.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.303 seconds
[2025-11-02T09:57:19.775+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:57:19.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:57:19.779+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:57:19.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:57:19.810+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:57:19.878+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:57:19.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:57:19.945+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:57:19.945+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:57:19.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.226 seconds
[2025-11-02T09:57:50.889+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:57:50.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:57:50.892+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:57:50.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:57:50.915+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:57:50.977+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:57:50.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:57:51.026+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:57:51.026+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:57:51.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.194 seconds
[2025-11-02T09:58:22.301+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:58:22.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:58:22.304+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:58:22.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:58:22.337+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:58:22.446+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:58:22.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:58:22.518+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:58:22.517+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:58:22.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.276 seconds
[2025-11-02T09:58:53.789+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:58:53.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:58:53.796+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:58:53.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:58:53.838+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:58:53.951+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:58:53.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:58:54.018+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:58:54.018+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:58:54.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.291 seconds
[2025-11-02T09:59:25.673+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:59:25.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:59:25.680+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:59:25.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:59:25.718+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:59:25.798+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:59:25.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:59:25.850+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:59:25.850+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:59:25.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.225 seconds
[2025-11-02T09:59:56.742+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:59:56.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T09:59:56.745+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:59:56.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:59:56.774+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T09:59:56.829+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:59:56.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T09:59:56.876+0000] {logging_mixin.py:190} INFO - [2025-11-02T09:59:56.875+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T09:59:56.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.186 seconds
[2025-11-02T10:00:28.081+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:00:28.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:00:28.084+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:00:28.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:00:28.118+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:00:28.201+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:00:28.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:00:28.283+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:00:28.282+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:00:28.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.258 seconds
[2025-11-02T10:00:59.398+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:00:59.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:00:59.402+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:00:59.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:00:59.434+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:00:59.502+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:00:59.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:00:59.554+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:00:59.553+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:00:59.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.219 seconds
[2025-11-02T10:01:30.760+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:01:30.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:01:30.763+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:01:30.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:01:30.795+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:01:30.862+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:01:30.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:01:30.941+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:01:30.941+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:01:30.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.247 seconds
[2025-11-02T10:02:03.385+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:02:03.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:02:03.388+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:02:03.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:02:03.417+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:02:03.479+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:02:03.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:02:03.525+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:02:03.525+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:02:03.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.183 seconds
[2025-11-02T10:02:34.681+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:02:34.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:02:34.685+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:02:34.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:02:34.706+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:02:34.747+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:02:34.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:02:34.783+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:02:34.783+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:02:34.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.138 seconds
[2025-11-02T10:03:05.738+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:03:05.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:03:05.743+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:03:05.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:03:05.794+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:03:05.868+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:03:05.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:03:05.920+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:03:05.920+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:03:05.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.241 seconds
[2025-11-02T10:03:37.055+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:03:37.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:03:37.059+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:03:37.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:03:37.091+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:03:37.148+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:03:37.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:03:37.192+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:03:37.192+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:03:37.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.206 seconds
[2025-11-02T10:04:08.455+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:04:08.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:04:08.460+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:04:08.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:04:08.496+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:04:08.572+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:04:08.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:04:08.678+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:04:08.678+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:04:08.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.300 seconds
[2025-11-02T10:04:39.894+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:04:39.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:04:39.897+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:04:39.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:04:39.925+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:04:39.980+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:04:39.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:04:40.023+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:04:40.023+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:04:40.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-02T10:05:10.377+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:05:10.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:05:10.383+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:05:10.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:05:10.420+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:05:10.489+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:05:10.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:05:10.536+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:05:10.536+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:05:10.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.222 seconds
[2025-11-02T10:05:41.002+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:05:41.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:05:41.007+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:05:41.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:05:41.055+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:05:41.134+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:05:41.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:05:41.205+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:05:41.205+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:05:41.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.299 seconds
[2025-11-02T10:06:12.020+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:06:12.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:06:12.024+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:06:12.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:06:12.066+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:06:12.113+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:06:12.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:06:12.148+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:06:12.148+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:06:12.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.165 seconds
[2025-11-02T10:06:42.329+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:06:42.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:06:42.332+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:06:42.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:06:42.353+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:06:42.405+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:06:42.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:06:42.446+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:06:42.446+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:06:42.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.160 seconds
[2025-11-02T10:07:12.553+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:07:12.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:07:12.556+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:07:12.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:07:12.576+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:07:12.623+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:07:12.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:07:12.665+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:07:12.665+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:07:12.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.146 seconds
[2025-11-02T10:07:42.866+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:07:42.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:07:42.868+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:07:42.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:07:42.890+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:07:42.933+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:07:42.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:07:42.980+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:07:42.980+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:07:43.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.179 seconds
[2025-11-02T10:08:13.359+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:08:13.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:08:13.366+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:08:13.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:08:13.401+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:08:13.496+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:08:13.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:08:13.553+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:08:13.553+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:08:13.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.271 seconds
[2025-11-02T10:08:43.680+0000] {processor.py:186} INFO - Started process (PID=472) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:08:43.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:08:43.691+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:08:43.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:08:43.724+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:08:43.774+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:08:43.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:08:43.828+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:08:43.828+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:08:43.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.196 seconds
[2025-11-02T10:09:13.938+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:09:13.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:09:13.941+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:09:13.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:09:13.972+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:09:14.036+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:09:14.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:09:14.078+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:09:14.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:09:14.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.178 seconds
[2025-11-02T10:09:44.240+0000] {processor.py:186} INFO - Started process (PID=480) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:09:44.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:09:44.243+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:09:44.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:09:44.272+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:09:44.380+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:09:44.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:09:44.488+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:09:44.487+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:09:44.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.336 seconds
[2025-11-02T10:10:14.840+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:10:14.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:10:14.844+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:10:14.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:10:14.873+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:10:14.930+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:10:14.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:10:14.975+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:10:14.975+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:10:15.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.183 seconds
[2025-11-02T10:10:45.590+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:10:45.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:10:45.593+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:10:45.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:10:45.623+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:10:45.682+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:10:45.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:10:45.738+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:10:45.738+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:10:45.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.201 seconds
[2025-11-02T10:11:16.617+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:11:16.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:11:16.620+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:11:16.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:11:16.646+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:11:16.698+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:11:16.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:11:16.741+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:11:16.741+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:11:16.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.172 seconds
[2025-11-02T10:11:46.969+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:11:46.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:11:46.975+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:11:46.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:11:47.031+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:11:47.085+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:11:47.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:11:47.121+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:11:47.121+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:11:47.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.195 seconds
[2025-11-02T10:12:17.469+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:12:17.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:12:17.482+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:12:17.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:12:17.549+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:12:17.804+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:12:17.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:12:17.886+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:12:17.886+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:12:17.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.482 seconds
[2025-11-02T10:12:48.138+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:12:48.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:12:48.142+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:12:48.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:12:48.178+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:12:48.247+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:12:48.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:12:48.333+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:12:48.333+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:12:48.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.265 seconds
[2025-11-02T10:13:18.445+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:13:18.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:13:18.448+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:13:18.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:13:18.468+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:13:18.510+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:13:18.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:13:18.551+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:13:18.551+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:13:18.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.155 seconds
[2025-11-02T10:13:48.664+0000] {processor.py:186} INFO - Started process (PID=512) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:13:48.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:13:48.668+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:13:48.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:13:48.704+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:13:48.802+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:13:48.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:13:48.863+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:13:48.863+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:13:48.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.266 seconds
[2025-11-02T10:14:19.217+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:14:19.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:14:19.219+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:14:19.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:14:19.248+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:14:19.312+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:14:19.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:14:19.362+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:14:19.361+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:14:19.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.193 seconds
[2025-11-02T10:14:49.565+0000] {processor.py:186} INFO - Started process (PID=520) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:14:49.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:14:49.567+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:14:49.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:14:49.588+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:14:49.636+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:14:49.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:14:49.675+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:14:49.675+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:14:49.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.162 seconds
[2025-11-02T10:15:19.899+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:15:19.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:15:19.901+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:15:19.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:15:19.922+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:15:19.978+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:15:19.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:15:20.027+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:15:20.027+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:15:20.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.177 seconds
[2025-11-02T10:15:50.321+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:15:50.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:15:50.325+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:15:50.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:15:50.358+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:15:50.423+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:15:50.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:15:50.484+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:15:50.484+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:15:50.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.239 seconds
[2025-11-02T10:16:20.899+0000] {processor.py:186} INFO - Started process (PID=532) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:16:20.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:16:20.903+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:16:20.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:16:20.940+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:16:21.000+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:16:21.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:16:21.040+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:16:21.040+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:16:21.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.197 seconds
[2025-11-02T10:16:51.283+0000] {processor.py:186} INFO - Started process (PID=536) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:16:51.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:16:51.287+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:16:51.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:16:51.309+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:16:51.368+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:16:51.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:16:51.414+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:16:51.414+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:16:51.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.177 seconds
[2025-11-02T10:17:21.556+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:17:21.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:17:21.559+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:17:21.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:17:21.580+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:17:21.629+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:17:21.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:17:21.670+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:17:21.670+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:17:21.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.159 seconds
[2025-11-02T10:17:52.007+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:17:52.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:17:52.011+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:17:52.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:17:52.055+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:17:52.141+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:17:52.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:17:52.235+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:17:52.235+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:17:52.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.295 seconds
[2025-11-02T10:18:22.610+0000] {processor.py:186} INFO - Started process (PID=548) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:18:22.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:18:22.615+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:18:22.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:18:22.647+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:18:22.711+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:18:22.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:18:22.768+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:18:22.768+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:18:22.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.231 seconds
[2025-11-02T10:18:53.361+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:18:53.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:18:53.365+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:18:53.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:18:53.398+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:18:53.453+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:18:53.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:18:53.517+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:18:53.517+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:18:53.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.206 seconds
[2025-11-02T10:19:23.643+0000] {processor.py:186} INFO - Started process (PID=556) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:19:23.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:19:23.645+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:19:23.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:19:23.664+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:19:23.704+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:19:23.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:19:23.730+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:19:23.730+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:19:23.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.120 seconds
[2025-11-02T10:19:53.819+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:19:53.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_datalake_dag.py for tasks to queue
[2025-11-02T10:19:53.821+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:19:53.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:19:53.838+0000] {processor.py:925} INFO - DAG(s) 'etl_datalake_hive_iceberg' retrieved from /opt/airflow/dags/etl_datalake_dag.py
[2025-11-02T10:19:53.872+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:19:53.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-11-02T10:19:53.899+0000] {logging_mixin.py:190} INFO - [2025-11-02T10:19:53.899+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_datalake_hive_iceberg to 2025-11-01T00:00:00+00:00, run_after=2025-11-02T00:00:00+00:00
[2025-11-02T10:19:53.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_datalake_dag.py took 0.110 seconds
